{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gensim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pymorphy2\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = gensim.models.KeyedVectors.load_word2vec_format('E:\\Programming\\DL_CurseWork\\embeding_weights.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sents</th>\n",
       "      <th>mark</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>обязательно посетить большой спасибо хозяйка г...</td>\n",
       "      <td>10</td>\n",
       "      <td>[обязательно, посетить, большой, спасибо, хозя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>приветливый берег приехать ребёнок семья ул . ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[приветливый, берег, приехать, ребёнок, семья,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sents  mark  \\\n",
       "0  обязательно посетить большой спасибо хозяйка г...    10   \n",
       "1  приветливый берег приехать ребёнок семья ул . ...     3   \n",
       "\n",
       "                                              tokens  \n",
       "0  [обязательно, посетить, большой, спасибо, хозя...  \n",
       "1  [приветливый, берег, приехать, ребёнок, семья,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokens = pd.read_csv('E:\\Programming\\DL_CurseWork\\dataset_mor.csv', index_col=0)\n",
    "\n",
    "dataset_tokens['tokens'] = dataset_tokens['sents'].astype('str').map(lambda x: x.split())\n",
    "dataset_tokens.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3778, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset_tokens['tokens'], dataset_tokens['mark'], test_size=0.2, random_state=268)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "  def __init__(self, X, y, vocab: gensim.models.KeyedVectors):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.vocab = vocab\n",
    "    self.max_len = 500\n",
    "    self.morth = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "  def vectorize(self, tokens):\n",
    "    if type(tokens) == str: tokens = [self.morth.parse(w)[0].normal_form for w in nltk.word_tokenize(tokens.lower())]\n",
    "    \n",
    "    tokens = tokens if len(tokens) <= self.max_len else tokens[:self.max_len]\n",
    "    \n",
    "    if len(tokens) != self.max_len:\n",
    "      tokens.extend(['.']*(self.max_len - len(tokens)))\n",
    "    \n",
    "    vec = torch.LongTensor([self.vocab.key_to_index[token] if token in self.vocab.key_to_index else 1 for token in tokens]).cuda()\n",
    "    \n",
    "    return vec\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \n",
    "    y = 0\n",
    "    if 6 < self.y.iloc[idx] <= 10: y = 1\n",
    "    \n",
    "    return self.vectorize(self.X.iloc[idx]), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(x_train, y_train, model_w2v)\n",
    "test_dataset = ReviewDataset(x_test, y_test, model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingNet(nn.Module):\n",
    "\n",
    "  def __init__(self, embeding_m, hidden_size, n_classes):\n",
    "    super(RatingNet, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embeding_m.vectors).cuda())\n",
    "    self.rnn = nn.RNN(300, hidden_size,batch_first=True).to('cuda:0')\n",
    "    self.flat = nn.Flatten().to('cuda:0')\n",
    "    self.fc = nn.Linear(in_features=hidden_size, out_features=n_classes).to('cuda:0')\n",
    "    self.softmax = nn.Softmax()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.embedding(x)\n",
    "    _, out = self.rnn(out)\n",
    "    out = out.permute(1,0,2)\n",
    "    out = self.flat(out)\n",
    "    out = self.fc(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "hidden = 64\n",
    "n_classes = 2\n",
    "model = RatingNet(embeding_m=model_w2v, hidden_size=hidden, n_classes=n_classes)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor([2, 1]).cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 500, 300])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.5 (20221223.1930)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"490pt\" height=\"402pt\"\n",
       " viewBox=\"0.00 0.00 490.00 402.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 398)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-398 486,-398 486,4 -4,4\"/>\n",
       "<!-- 2837159485632 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2837159485632</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"280,-31 221,-31 221,0 280,0 280,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"250.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (8, 2)</text>\n",
       "</g>\n",
       "<!-- 2837153800368 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2837153800368</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"301,-86 200,-86 200,-67 301,-67 301,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"250.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 2837153800368&#45;&gt;2837159485632 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>2837153800368&#45;&gt;2837159485632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.5,-66.54C250.5,-60.07 250.5,-50.98 250.5,-42.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254,-42.58 250.5,-32.58 247,-42.58 254,-42.58\"/>\n",
       "</g>\n",
       "<!-- 2837153804352 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2837153804352</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"161,-141 60,-141 60,-122 161,-122 161,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"110.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837153804352&#45;&gt;2837153800368 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2837153804352&#45;&gt;2837153800368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.25,-121.51C156.81,-112.97 190.97,-100.03 216.44,-90.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"217.57,-93.71 225.69,-86.89 215.09,-87.16 217.57,-93.71\"/>\n",
       "</g>\n",
       "<!-- 2837160199168 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2837160199168</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"140,-207 81,-207 81,-177 140,-177 140,-207\"/>\n",
       "<text text-anchor=\"middle\" x=\"110.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">fc.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"110.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
       "</g>\n",
       "<!-- 2837160199168&#45;&gt;2837153804352 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2837160199168&#45;&gt;2837153804352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.5,-176.54C110.5,-169.34 110.5,-160.53 110.5,-152.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114,-152.69 110.5,-142.69 107,-152.69 114,-152.69\"/>\n",
       "</g>\n",
       "<!-- 2837153793264 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2837153793264</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"322,-141 179,-141 179,-122 322,-122 322,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"250.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ReshapeAliasBackward0</text>\n",
       "</g>\n",
       "<!-- 2837153793264&#45;&gt;2837153800368 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2837153793264&#45;&gt;2837153800368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.5,-121.75C250.5,-115.27 250.5,-106.16 250.5,-97.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254,-97.96 250.5,-87.96 247,-97.96 254,-97.96\"/>\n",
       "</g>\n",
       "<!-- 2837153802144 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2837153802144</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"307,-201.5 194,-201.5 194,-182.5 307,-182.5 307,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"250.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">PermuteBackward0</text>\n",
       "</g>\n",
       "<!-- 2837153802144&#45;&gt;2837153793264 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2837153802144&#45;&gt;2837153793264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.5,-182.37C250.5,-174.5 250.5,-162.6 250.5,-152.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254,-152.68 250.5,-142.68 247,-152.68 254,-152.68\"/>\n",
       "</g>\n",
       "<!-- 2837153792160 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2837153792160</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"310,-267.5 191,-267.5 191,-248.5 310,-248.5 310,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"250.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">CudnnRnnBackward0</text>\n",
       "</g>\n",
       "<!-- 2837153792160&#45;&gt;2837153802144 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2837153792160&#45;&gt;2837153802144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.5,-248.1C250.5,-239.12 250.5,-224.95 250.5,-213.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254,-213.34 250.5,-203.34 247,-213.34 254,-213.34\"/>\n",
       "</g>\n",
       "<!-- 2837153808288 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2837153808288</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"116,-328 15,-328 15,-309 116,-309 116,-328\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837153808288&#45;&gt;2837153792160 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2837153808288&#45;&gt;2837153792160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.6,-308.62C124.97,-298.69 175.98,-282.57 211.27,-271.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.22,-274.78 220.69,-268.42 210.11,-268.1 212.22,-274.78\"/>\n",
       "</g>\n",
       "<!-- 2837203913920 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2837203913920</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"113,-394 0,-394 0,-364 113,-364 113,-394\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_ih_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\"> (64, 300)</text>\n",
       "</g>\n",
       "<!-- 2837203913920&#45;&gt;2837153808288 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2837203913920&#45;&gt;2837153808288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.72,-363.54C59.85,-356.26 61.22,-347.31 62.44,-339.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.87,-340.09 63.94,-329.67 58.96,-339.02 65.87,-340.09\"/>\n",
       "</g>\n",
       "<!-- 2837153792112 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>2837153792112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"241,-328 140,-328 140,-309 241,-309 241,-328\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837153792112&#45;&gt;2837153792160 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2837153792112&#45;&gt;2837153792160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M199.61,-308.62C208.51,-299.94 222.28,-286.52 233.25,-275.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"235.5,-278.51 240.22,-269.03 230.61,-273.5 235.5,-278.51\"/>\n",
       "</g>\n",
       "<!-- 2837160198528 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>2837160198528</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"244,-394 131,-394 131,-364 244,-364 244,-394\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_hh_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\"> (64, 64)</text>\n",
       "</g>\n",
       "<!-- 2837160198528&#45;&gt;2837153792112 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2837160198528&#45;&gt;2837153792112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.24,-363.54C188.62,-356.26 189.07,-347.31 189.48,-339.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.96,-339.85 189.98,-329.69 185.97,-339.49 192.96,-339.85\"/>\n",
       "</g>\n",
       "<!-- 2837153799936 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>2837153799936</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"361,-328 260,-328 260,-309 361,-309 361,-328\"/>\n",
       "<text text-anchor=\"middle\" x=\"310.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837153799936&#45;&gt;2837153792160 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2837153799936&#45;&gt;2837153792160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.39,-308.62C292.49,-299.94 278.72,-286.52 267.75,-275.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"270.39,-273.5 260.78,-269.03 265.5,-278.51 270.39,-273.5\"/>\n",
       "</g>\n",
       "<!-- 2837160198688 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>2837160198688</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"363,-394 262,-394 262,-364 363,-364 363,-394\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_ih_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"312.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 2837160198688&#45;&gt;2837153799936 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2837160198688&#45;&gt;2837153799936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.01,-363.54C311.76,-356.34 311.46,-347.53 311.19,-339.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.69,-339.56 310.85,-329.69 307.69,-339.8 314.69,-339.56\"/>\n",
       "</g>\n",
       "<!-- 2837153806944 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>2837153806944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"481,-328 380,-328 380,-309 481,-309 481,-328\"/>\n",
       "<text text-anchor=\"middle\" x=\"430.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837153806944&#45;&gt;2837153792160 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2837153806944&#45;&gt;2837153792160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.16,-308.62C372.63,-298.69 323.01,-282.57 288.67,-271.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290.13,-268.2 279.53,-268.44 287.96,-274.86 290.13,-268.2\"/>\n",
       "</g>\n",
       "<!-- 2837160198608 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>2837160198608</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"482,-394 381,-394 381,-364 482,-364 482,-394\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_hh_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"431.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 2837160198608&#45;&gt;2837153806944 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>2837160198608&#45;&gt;2837153806944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M431.25,-363.54C431.13,-356.34 430.98,-347.53 430.84,-339.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"434.34,-339.63 430.67,-329.69 427.35,-339.75 434.34,-339.63\"/>\n",
       "</g>\n",
       "<!-- 2837153799360 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>2837153799360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"417,-141 340,-141 340,-122 417,-122 417,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 2837153799360&#45;&gt;2837153800368 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>2837153799360&#45;&gt;2837153800368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M356.79,-121.51C336.34,-113.04 305.48,-100.27 282.27,-90.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"283.87,-87.53 273.29,-86.94 281.19,-94 283.87,-87.53\"/>\n",
       "</g>\n",
       "<!-- 2837153806512 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>2837153806512</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"429,-201.5 328,-201.5 328,-182.5 429,-182.5 429,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837153806512&#45;&gt;2837153799360 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>2837153806512&#45;&gt;2837153799360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M378.5,-182.37C378.5,-174.5 378.5,-162.6 378.5,-152.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"382,-152.68 378.5,-142.68 375,-152.68 382,-152.68\"/>\n",
       "</g>\n",
       "<!-- 2837164566112 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>2837164566112</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"414,-273 343,-273 343,-243 414,-243 414,-273\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">fc.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"378.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (2, 64)</text>\n",
       "</g>\n",
       "<!-- 2837164566112&#45;&gt;2837153806512 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>2837164566112&#45;&gt;2837153806512</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M378.5,-242.8C378.5,-234.09 378.5,-222.81 378.5,-213.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"382,-213.36 378.5,-203.36 375,-213.36 382,-213.36\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x294938b55d0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(model(next(iter(train_loader))[0]), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Training loss: 0.6706932891140539 val_loss: 0.7168574929237366\n",
      "#5 Training loss: 0.6716204188645832 val_loss: 0.7176806926727295\n",
      "#10 Training loss: 0.6706694716972018 val_loss: 0.7268440127372742\n",
      "#15 Training loss: 0.6722691507724227 val_loss: 0.719812273979187\n",
      "#20 Training loss: 0.6729454219183594 val_loss: 0.7166316509246826\n",
      "#25 Training loss: 0.6749555832021451 val_loss: 0.7693430185317993\n",
      "#30 Training loss: 0.6729601609801489 val_loss: 0.7429118752479553\n",
      "#35 Training loss: 0.6707326130419181 val_loss: 0.7166550159454346\n",
      "#40 Training loss: 0.6731578946586639 val_loss: 0.7273474335670471\n",
      "#45 Training loss: 0.6727726594323203 val_loss: 0.7385109663009644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  epoch_loss = 0\n",
    "  for X_batch, y_batch in train_loader:\n",
    "    predictions = model(X_batch.cuda())\n",
    "    loss = criterion(predictions, y_batch.cuda()).cuda()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss += loss.item()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    val_loss, val_acc = 0, 0\n",
    "    for X_batch, y_batch in test_loader:\n",
    "      predictions = model(X_batch.cuda())\n",
    "      loss = criterion(predictions, y_batch.cuda()).item()\n",
    "      acc = accuracy_score(y_batch, predictions.argmax(dim=1).cpu().detach()).item()\n",
    "      val_loss += loss\n",
    "      val_acc += acc\n",
    "    \n",
    "    history.append(val_loss / len(test_loader))\n",
    "    if epoch % 5 == 0:\n",
    "      print(f'#{epoch} Training loss: {epoch_loss / len(train_loader)} val_loss: {val_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Динамика ошибки модели RNN')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history)\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Ошибка на тестовой выборке')\n",
    "plt.title('Динамика ошибки модели RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.99      0.56       295\n",
      "           1       0.56      0.01      0.02       461\n",
      "\n",
      "    accuracy                           0.39       756\n",
      "   macro avg       0.47      0.50      0.29       756\n",
      "weighted avg       0.49      0.39      0.23       756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch.cuda()).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingNetV2(nn.Module):\n",
    "\n",
    "  def __init__(self, embeding_m, hidden_size, n_classes):\n",
    "    super(RatingNetV2, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embeding_m.vectors).cuda())\n",
    "    self.rnn = nn.RNN(300, hidden_size, num_layers=2, batch_first=True, dropout=0.4).to('cuda:0')\n",
    "    self.flat = nn.Flatten().to('cuda:0')\n",
    "    self.fc = nn.Linear(in_features=hidden_size*2, out_features=n_classes).to('cuda:0')\n",
    "    self.softmax = nn.Softmax()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.embedding(x)\n",
    "    _, out = self.rnn(out)\n",
    "    out = out.permute(1,0,2)\n",
    "    out = self.flat(out)\n",
    "    out = self.fc(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "hidden = 256\n",
    "n_classes = 2\n",
    "model = RatingNetV2(embeding_m=model_w2v, hidden_size=hidden, n_classes=n_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Training loss: 0.7079287262032272 val_loss: 0.669529914855957\n",
      "#5 Training loss: 0.6943701587656819 val_loss: 0.6822196245193481\n",
      "#10 Training loss: 0.6852806555846381 val_loss: 0.6764397621154785\n",
      "#15 Training loss: 0.6864562977558721 val_loss: 0.7634286880493164\n",
      "#20 Training loss: 0.6802039379796023 val_loss: 0.6892499923706055\n",
      "#25 Training loss: 0.6911227806771874 val_loss: 0.707795262336731\n",
      "#30 Training loss: 0.6967849051826215 val_loss: 0.7007067799568176\n",
      "#35 Training loss: 0.6786437888467123 val_loss: 0.8477637767791748\n",
      "#40 Training loss: 0.6915426124182958 val_loss: 0.7738903164863586\n",
      "#45 Training loss: 0.667553426727416 val_loss: 0.7043823003768921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  epoch_loss = 0\n",
    "  for X_batch, y_batch in train_loader:\n",
    "    predictions = model(X_batch.cuda())\n",
    "    loss = criterion(predictions, y_batch.cuda()).cuda()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss += loss.item()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    val_loss, val_acc = 0, 0\n",
    "    for X_batch, y_batch in test_loader:\n",
    "      predictions = model(X_batch.cuda())\n",
    "      loss = criterion(predictions, y_batch.cuda()).item()\n",
    "      acc = accuracy_score(y_batch, predictions.argmax(dim=1).cpu().detach()).item()\n",
    "      val_loss += loss\n",
    "      val_acc += acc\n",
    "    \n",
    "    history.append(val_loss / len(test_loader))\n",
    "    if epoch % 5 == 0:\n",
    "      print(f'#{epoch} Training loss: {epoch_loss / len(train_loader)} val_loss: {val_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Динамика ошибки модели RNN')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history)\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Ошибка на тестовой выборке')\n",
    "plt.title('Динамика ошибки модели RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.02      0.04       295\n",
      "           1       0.61      0.99      0.76       461\n",
      "\n",
      "    accuracy                           0.61       756\n",
      "   macro avg       0.58      0.50      0.40       756\n",
      "weighted avg       0.59      0.61      0.48       756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch.cuda()).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.5 (20221223.1930)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"864pt\" height=\"399pt\"\n",
       " viewBox=\"0.00 0.00 864.00 398.84\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.872727 0.872727) rotate(0) translate(4 453)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-453 986,-453 986,4 -4,4\"/>\n",
       "<!-- 2842587670512 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2842587670512</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"524,-31 465,-31 465,0 524,0 524,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (8, 2)</text>\n",
       "</g>\n",
       "<!-- 2841786634144 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2841786634144</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"545,-86 444,-86 444,-67 545,-67 545,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 2841786634144&#45;&gt;2842587670512 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>2841786634144&#45;&gt;2842587670512</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M494.5,-66.54C494.5,-60.07 494.5,-50.98 494.5,-42.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"498,-42.58 494.5,-32.58 491,-42.58 498,-42.58\"/>\n",
       "</g>\n",
       "<!-- 2837125205392 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2837125205392</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"411,-141 310,-141 310,-122 411,-122 411,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837125205392&#45;&gt;2841786634144 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2837125205392&#45;&gt;2841786634144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383.23,-121.51C404.73,-113.01 437.23,-100.15 461.57,-90.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.69,-93.85 470.7,-86.91 460.11,-87.34 462.69,-93.85\"/>\n",
       "</g>\n",
       "<!-- 2842749541392 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2842749541392</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"390,-207 331,-207 331,-177 390,-177 390,-207\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">fc.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"360.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
       "</g>\n",
       "<!-- 2842749541392&#45;&gt;2837125205392 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2842749541392&#45;&gt;2837125205392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M360.5,-176.54C360.5,-169.34 360.5,-160.53 360.5,-152.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364,-152.69 360.5,-142.69 357,-152.69 364,-152.69\"/>\n",
       "</g>\n",
       "<!-- 2837125210240 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2837125210240</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"560,-141 429,-141 429,-122 560,-122 560,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">UnsafeViewBackward0</text>\n",
       "</g>\n",
       "<!-- 2837125210240&#45;&gt;2841786634144 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2837125210240&#45;&gt;2841786634144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M494.5,-121.75C494.5,-115.27 494.5,-106.16 494.5,-97.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"498,-97.96 494.5,-87.96 491,-97.96 498,-97.96\"/>\n",
       "</g>\n",
       "<!-- 2837124639200 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2837124639200</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"545,-201.5 444,-201.5 444,-182.5 545,-182.5 545,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">CloneBackward0</text>\n",
       "</g>\n",
       "<!-- 2837124639200&#45;&gt;2837125210240 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2837124639200&#45;&gt;2837125210240</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M494.5,-182.37C494.5,-174.5 494.5,-162.6 494.5,-152.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"498,-152.68 494.5,-142.68 491,-152.68 498,-152.68\"/>\n",
       "</g>\n",
       "<!-- 2837243016432 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2837243016432</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"551,-267.5 438,-267.5 438,-248.5 551,-248.5 551,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">PermuteBackward0</text>\n",
       "</g>\n",
       "<!-- 2837243016432&#45;&gt;2837124639200 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2837243016432&#45;&gt;2837124639200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M494.5,-248.1C494.5,-239.12 494.5,-224.95 494.5,-213.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"498,-213.34 494.5,-203.34 491,-213.34 498,-213.34\"/>\n",
       "</g>\n",
       "<!-- 2837243015616 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2837243015616</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"554,-328 435,-328 435,-309 554,-309 554,-328\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">CudnnRnnBackward0</text>\n",
       "</g>\n",
       "<!-- 2837243015616&#45;&gt;2837243016432 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2837243015616&#45;&gt;2837243016432</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M494.5,-308.87C494.5,-301 494.5,-289.1 494.5,-278.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"498,-279.18 494.5,-269.18 491,-279.18 498,-279.18\"/>\n",
       "</g>\n",
       "<!-- 2837243013600 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2837243013600</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"116,-383 15,-383 15,-364 116,-364 116,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837243013600&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2837243013600&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116.37,-366.13C122.15,-365.41 127.95,-364.69 133.5,-364 234.18,-351.5 350.67,-337.17 423.47,-328.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"423.77,-331.71 433.27,-327.02 422.92,-324.76 423.77,-331.71\"/>\n",
       "</g>\n",
       "<!-- 2842747974288 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>2842747974288</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"113,-449 0,-449 0,-419 113,-419 113,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_ih_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256, 300)</text>\n",
       "</g>\n",
       "<!-- 2842747974288&#45;&gt;2837243013600 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2842747974288&#45;&gt;2837243013600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.72,-418.54C59.85,-411.26 61.22,-402.31 62.44,-394.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.87,-395.09 63.94,-384.67 58.96,-394.02 65.87,-395.09\"/>\n",
       "</g>\n",
       "<!-- 2837243011824 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>2837243011824</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"244,-383 143,-383 143,-364 244,-364 244,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837243011824&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2837243011824&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.22,-363.57C296.1,-354.43 376.78,-340.23 432.44,-330.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.84,-333.91 442.08,-328.73 431.63,-327.02 432.84,-333.91\"/>\n",
       "</g>\n",
       "<!-- 2842748067552 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>2842748067552</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"244,-449 131,-449 131,-419 244,-419 244,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_hh_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256, 256)</text>\n",
       "</g>\n",
       "<!-- 2842748067552&#45;&gt;2837243011824 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2842748067552&#45;&gt;2837243011824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.98,-418.54C189.73,-411.26 190.65,-402.31 191.46,-394.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.92,-394.99 192.46,-384.68 187.95,-394.27 194.92,-394.99\"/>\n",
       "</g>\n",
       "<!-- 2837243014416 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>2837243014416</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"366,-383 265,-383 265,-364 366,-364 366,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837243014416&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2837243014416&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M345.86,-363.51C375.4,-354.76 420.48,-341.42 453.25,-331.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"454.24,-335.07 462.83,-328.88 452.25,-328.36 454.24,-335.07\"/>\n",
       "</g>\n",
       "<!-- 2842670059248 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>2842670059248</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"363,-449 262,-449 262,-419 363,-419 363,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_ih_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"312.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 2842670059248&#45;&gt;2837243014416 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2842670059248&#45;&gt;2837243014416</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M313.24,-418.54C313.62,-411.26 314.07,-402.31 314.48,-394.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"317.96,-394.85 314.98,-384.69 310.97,-394.49 317.96,-394.85\"/>\n",
       "</g>\n",
       "<!-- 2842276282576 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>2842276282576</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"485,-383 384,-383 384,-364 485,-364 485,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"434.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2842276282576&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>2842276282576&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M444.68,-363.51C453.26,-355.93 465.77,-344.88 476.1,-335.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"478.16,-338.6 483.34,-329.36 473.53,-333.36 478.16,-338.6\"/>\n",
       "</g>\n",
       "<!-- 2842587670272 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>2842587670272</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"482,-449 381,-449 381,-419 482,-419 482,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_hh_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"431.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 2842587670272&#45;&gt;2842276282576 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>2842587670272&#45;&gt;2842276282576</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M432.24,-418.54C432.62,-411.26 433.07,-402.31 433.48,-394.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"436.96,-394.85 433.98,-384.69 429.97,-394.49 436.96,-394.85\"/>\n",
       "</g>\n",
       "<!-- 2842276282864 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>2842276282864</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"605,-383 504,-383 504,-364 605,-364 605,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"554.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2842276282864&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>2842276282864&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M544.32,-363.51C535.74,-355.93 523.23,-344.88 512.9,-335.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"515.47,-333.36 505.66,-329.36 510.84,-338.6 515.47,-333.36\"/>\n",
       "</g>\n",
       "<!-- 2842749435968 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>2842749435968</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"613,-449 500,-449 500,-419 613,-419 613,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_ih_l1</text>\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256, 256)</text>\n",
       "</g>\n",
       "<!-- 2842749435968&#45;&gt;2842276282864 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>2842749435968&#45;&gt;2842276282864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M556.01,-418.54C555.76,-411.34 555.46,-402.53 555.19,-394.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"558.69,-394.56 554.85,-384.69 551.69,-394.8 558.69,-394.56\"/>\n",
       "</g>\n",
       "<!-- 2842276285168 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>2842276285168</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"731,-383 630,-383 630,-364 731,-364 731,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"680.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2842276285168&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>2842276285168&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M648.95,-363.51C618.13,-354.73 571,-341.3 536.91,-331.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"537.93,-328.24 527.35,-328.86 536.01,-334.97 537.93,-328.24\"/>\n",
       "</g>\n",
       "<!-- 2842749450368 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>2842749450368</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"744,-449 631,-449 631,-419 744,-419 744,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"687.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_hh_l1</text>\n",
       "<text text-anchor=\"middle\" x=\"687.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256, 256)</text>\n",
       "</g>\n",
       "<!-- 2842749450368&#45;&gt;2842276285168 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>2842749450368&#45;&gt;2842276285168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M685.77,-418.54C684.9,-411.26 683.83,-402.31 682.88,-394.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"686.38,-394.19 681.72,-384.68 679.43,-395.02 686.38,-394.19\"/>\n",
       "</g>\n",
       "<!-- 2837885343088 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>2837885343088</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"856,-383 755,-383 755,-364 856,-364 856,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"805.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837885343088&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>2837885343088&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M754.84,-363.87C701.27,-354.74 616.62,-340.31 558.48,-330.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"559.16,-326.97 548.71,-328.74 557.98,-333.87 559.16,-326.97\"/>\n",
       "</g>\n",
       "<!-- 2842749444928 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>2842749444928</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"863,-449 762,-449 762,-419 863,-419 863,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"812.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_ih_l1</text>\n",
       "<text text-anchor=\"middle\" x=\"812.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 2842749444928&#45;&gt;2837885343088 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>2842749444928&#45;&gt;2837885343088</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M810.77,-418.54C809.9,-411.26 808.83,-402.31 807.88,-394.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"811.38,-394.19 806.72,-384.68 804.43,-395.02 811.38,-394.19\"/>\n",
       "</g>\n",
       "<!-- 2837885344816 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>2837885344816</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"978,-383 877,-383 877,-364 978,-364 978,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"927.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837885344816&#45;&gt;2837243015616 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>2837885344816&#45;&gt;2837243015616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M876.76,-365.47C872.95,-364.97 869.16,-364.47 865.5,-364 761.15,-350.59 640.12,-336.31 565.43,-327.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"566.14,-324.21 555.8,-326.53 565.33,-331.16 566.14,-324.21\"/>\n",
       "</g>\n",
       "<!-- 2842749446928 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>2842749446928</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"982,-449 881,-449 881,-419 982,-419 982,-449\"/>\n",
       "<text text-anchor=\"middle\" x=\"931.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_hh_l1</text>\n",
       "<text text-anchor=\"middle\" x=\"931.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 2842749446928&#45;&gt;2837885344816 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>2842749446928&#45;&gt;2837885344816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M930.51,-418.54C930.01,-411.26 929.4,-402.31 928.86,-394.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"932.37,-394.42 928.2,-384.69 925.39,-394.9 932.37,-394.42\"/>\n",
       "</g>\n",
       "<!-- 2837125212784 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>2837125212784</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"655,-141 578,-141 578,-122 655,-122 655,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 2837125212784&#45;&gt;2841786634144 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>2837125212784&#45;&gt;2841786634144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M595.8,-121.51C576.5,-113.12 547.44,-100.5 525.39,-90.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"526.84,-87.74 516.28,-86.96 524.06,-94.16 526.84,-87.74\"/>\n",
       "</g>\n",
       "<!-- 2837243014032 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>2837243014032</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"667,-201.5 566,-201.5 566,-182.5 667,-182.5 667,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2837243014032&#45;&gt;2837125212784 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>2837243014032&#45;&gt;2837125212784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M616.5,-182.37C616.5,-174.5 616.5,-162.6 616.5,-152.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"620,-152.68 616.5,-142.68 613,-152.68 620,-152.68\"/>\n",
       "</g>\n",
       "<!-- 2842747963488 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>2842747963488</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"652,-273 581,-273 581,-243 652,-243 652,-273\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">fc.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (2, 512)</text>\n",
       "</g>\n",
       "<!-- 2842747963488&#45;&gt;2837243014032 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>2842747963488&#45;&gt;2837243014032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M616.5,-242.8C616.5,-234.09 616.5,-222.81 616.5,-213.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"620,-213.36 616.5,-203.36 613,-213.36 620,-213.36\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x294bf251270>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(model(next(iter(train_loader))[0]), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeding_m, hidden_dim, output_dim, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding  = nn.Embedding.from_pretrained(torch.FloatTensor(embeding_m.vectors).cuda())\n",
    "        \n",
    "        self.lstm = nn.LSTM(300, \n",
    "                            hidden_dim,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.embedding(x))\n",
    "        \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        x = lstm_out[:, -1, :]\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(16523, 300)\n",
       "  (lstm): LSTM(300, 256, batch_first=True, dropout=0.4)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(\n",
    "    embeding_m=model_w2v,\n",
    "    hidden_dim=256,\n",
    "    output_dim=2,\n",
    "    dropout=0.4\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to('cuda')\n",
    "criterion = criterion.to('cuda')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(model(next(iter(train_loader))[0]), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Training loss: 0.6742252830475096 val_loss: 0.6686657294631004\n",
      "#2 Training loss: 0.6630731280203219 val_loss: 0.6695619908471903\n",
      "#4 Training loss: 0.6555353863529427 val_loss: 0.672660389294227\n",
      "#6 Training loss: 0.6496923373489784 val_loss: 0.6867014393210411\n",
      "#8 Training loss: 0.6512941263970875 val_loss: 0.67340487241745\n",
      "#10 Training loss: 0.5802059476337735 val_loss: 0.7224913847943147\n",
      "#12 Training loss: 0.5194549207334165 val_loss: 0.45877917980154354\n",
      "#14 Training loss: 0.4242895198641 val_loss: 0.40380120494713384\n",
      "#16 Training loss: 0.3418846541138553 val_loss: 0.3599982224404812\n",
      "#18 Training loss: 0.3225045193518911 val_loss: 0.36259037248479825\n",
      "#20 Training loss: 0.3069917577166091 val_loss: 0.3679224541410804\n",
      "#22 Training loss: 0.27382063475393115 val_loss: 0.35539346917842823\n",
      "#24 Training loss: 0.25651201073612484 val_loss: 0.3918691510334611\n",
      "#26 Training loss: 0.22485252408675416 val_loss: 0.35415185739596683\n",
      "#28 Training loss: 0.2190631237965097 val_loss: 0.3110331300025185\n",
      "#30 Training loss: 0.19075021600084646 val_loss: 0.32775432399163645\n",
      "#32 Training loss: 0.16727752975685886 val_loss: 0.3548771314478169\n",
      "#34 Training loss: 0.14990062358734943 val_loss: 0.32780776894651353\n",
      "#36 Training loss: 0.13405392781668712 val_loss: 0.35791322914883494\n",
      "#38 Training loss: 0.1220084977134195 val_loss: 0.3893038157063226\n",
      "#40 Training loss: 0.09725727915527328 val_loss: 0.3832392608746886\n",
      "#42 Training loss: 0.1069201187171515 val_loss: 0.3886400763100634\n",
      "#44 Training loss: 0.09169727861979808 val_loss: 0.43076481961179525\n",
      "#46 Training loss: 0.09223130825049584 val_loss: 0.38977992682096857\n",
      "#48 Training loss: 0.08698948895282767 val_loss: 0.39290417919013026\n",
      "#50 Training loss: 0.058314820197189136 val_loss: 0.45828028841060586\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50 + 1\n",
    "\n",
    "history = []\n",
    "\n",
    "save = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        predictions = model(X_batch.cuda())\n",
    "        loss = criterion(predictions, y_batch.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = 0, 0\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            predictions = model(X_batch.cuda())\n",
    "            loss = criterion(predictions, y_batch.cuda()).item()\n",
    "            acc = accuracy_score(y_batch, predictions.argmax(dim=1).cpu().detach()).item()\n",
    "            val_loss += loss\n",
    "            val_acc += acc\n",
    "      \n",
    "    history.append(val_loss / len(test_loader))\n",
    "    if epoch % 2 == 0:\n",
    "      print(f'#{epoch} Training loss: {epoch_loss / len(train_loader)} val_loss: {val_loss / len(test_loader)}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       295\n",
      "           1       0.86      0.94      0.90       461\n",
      "\n",
      "    accuracy                           0.87       756\n",
      "   macro avg       0.88      0.85      0.86       756\n",
      "weighted avg       0.87      0.87      0.87       756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch.cuda()).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Динамика ошибки модели RNN')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHGCAYAAACIDqqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6eklEQVR4nO3dd3xT9foH8M9J2nQ33bt0sEtZtgJlimwVQa/KFRW4oleuIOAe6A9F7wVxAQo4LoI4UVHEKwgoe8poWS2b0tI9aJuupEnO7480aUtX0iZNk37er1de0pOTk6fHjqff7/N9voIoiiKIiIiI7ITE2gEQERERmROTGyIiIrIrTG6IiIjIrjC5ISIiIrvC5IaIiIjsCpMbIiIisitMboiIiMiuMLkhIiIiu8LkhoiIiOwKkxsishuiKKK0tBQVFRXWDoWIrIjJDRHZLFEUsX79eowbNw7BwcGQyWTw8PDABx98YO3QiMiKmNyQzfrxxx8hCEKDj9jYWGuHRxam1Wrxt7/9DTNmzEBERAS++OILHDp0CMeOHcPcuXOtHR7dJDIyss73qJubG2655RZ89NFHuHmLw927dxvOO3ToUL1rzZgxA+7u7nWO3XbbbRAEAePHj693fmpqKgRBwLvvvmveT4raLQdrB0DUWitXrsQtt9xi+PjJJ5+ESqWyYkTUFpYvX46ff/4Za9euxYwZM6wdDhlhyJAhhgQjMzMT77//Pp566imUlJTglVdeafA1L7zwAvbt22f0e2zbtg07d+7E7bffbpaYyTZx5IZslv6vvV69emHQoEGGh6enp5Ujo7bwwQcfYMKECUxsbIiXl5fh+/Tee+/Fli1bIJfL8cknnzR4/vjx47F//378+uuvRl2/W7duiI6OxgsvvFBvNIg6FiY3ZLOUSiUAwMGh+QHIdevWQRAEpKamGo5VVVWhZ8+eEAQB69atMxxvaMgbqJkG2717t+HYjh07MGnSJISFhcHZ2RldunTBE088gfz8/Dqvff311yEIAvz8/FBZWVnnuS+++MIwBF/7dZGRkfV+cX/55ZcQBAGRkZGGY/oh99qfQ35+Pvr06YOePXsiOzvbcHzlypUYPnw4AgIC4Obmht69e2Pp0qWoqqpq4u7V2L9/P0aNGgUPDw+4urpi8ODB+O233+qco7/Xx44dqxOPIAh4/fXX65w7aNAgxMfHGz7WT0fUvscAMHr06DqvLywsRHp6OsLDw3HfffchJCQELi4uuOWWW/DNN9/UeW1D17x8+TLCw8MxbNgwlJaWNnofAWDmzJkQBKHZJEr/ekEQ8MMPP9R5rrS0FHK5vMGpEWPuqd6MGTManIZtKLYNGzYgISEBbm5ucHd3x7hx45CYmNjgdRub3q39/dLQ/78333wTgiDgtttua/LeNMbT0xPdunVDTk5Oo59vTEwMXn75ZWg0mmav5+joiH//+984fvw4NmzY0KKYyD4wuSGbpU8SnJycWvT6Dz74ABcvXmxVDJcvX0ZCQgJWr16N7du34//+7/9w5MgRDB06tMGEQRTFer98V65cCV9f32bfq6SkBC+88AKkUmmT5+Xn5+P2229HVVUVdu3ahaCgoDrxTp06FV9++SX+97//YebMmXjnnXfwxBNPNPv+e/bswe23347i4mKsWbMG3377LTw8PDBx4kSL/iL5/vvv6yU75eXlAIBPP/0Up0+fxjvvvIMff/wRUVFReOihh/Dhhx82er3Lly/jtttuQ2RkJLZu3dpgIqt35MgRrF27ttl7XpuPj0+99//iiy/g6OhY79yW3FMXFxccOnTI8HBxcal3zn/+8x88+OCDiImJwffff48vv/wSCoUCw4YNQ3JycoPXnTlzpuGar776arOf57Vr17B48WKT7s3N1Go10tPT0a1btwafl0qlWLx4Mc6ePYsvvvjCqGtOmTIFcXFxePXVV41O2sn+MLkhm6Uf5fDy8jL5tRkZGXjzzTcxe/bsVsUwa9YsvPTSS5g4cSKGDRuGqVOnYvPmzTh//jy2bt1a7/yZM2fio48+Mnx85MgRnD59GlOnTm32vRYuXAipVIrJkyc3ek5+fj5GjRrVYGIDAO+//z5mzZqFcePGYcSIEZgzZw7ef/99rF+/Hjdu3Gjy/V966SV4e3tj9+7deOCBBzBp0iRs2bIFvXr1wnPPPWeRaYCysjI8++yz9f4/6X+hu7i4YM+ePXjooYdw5513YuPGjRg+fDhee+21BpeDX7lyBSNHjjQqsdFqtZg9ezYmTpyIsLAwo2OePn06Dh8+jFOnThmOrVy5EjNnzqx3rqn3VKlUwtHRsc40rERS98d4eno6Fi5ciDlz5mDNmjW48847cc8992D79u3w8PDAG2+8Ued8fX1aZGSk4ZqdO3du9vOcP38+evTogcGDBxt9b0RRhFqthlqtRlpaGp588kkUFBRg8eLFjb7m7rvvxtChQ7Fw4cJ6o54NEQQBb7/9Ni5fvtzodBfZPyY3ZLP00y2BgYEmv/aZZ55BZGQknnrqqUbP0f8Q1j+0Wm29c3JzczFr1iyEh4fDwcEBjo6OiIiIAACkpKTUO/+xxx7DuXPncODAAQDAhx9+iAcffBA+Pj5NxnvmzBl89NFHeO+99xr9hVxQUIBRo0bh1KlT2LhxY73EBgASExNx9913w9fXF1KpFI6Ojpg2bRo0Gg0uXLjQ6PuXlZXhyJEjuO++++q8v1QqxSOPPILr16/j/PnzTX4OLbFo0SJUVVVh0aJFdY7LZDIAwJgxY+p9ntOnT0dxcTGOHz9e5/iVK1dw2223IT8/H5s2bWoysQGATz75BMnJyVi2bJlJMYeEhOCee+4xjN788ccfyMjIwCOPPFLnvJbc09LSUri6ujb5/tu2bYNarca0adPqfP06OztjxIgR9UbB9Emgs7Oz0Z/j77//jl9++QUrV66sl1w1ZcuWLXB0dDR8n3z22Wf48MMPceeddzb5urfffhvXr1/H8uXLjXqfUaNGYezYsVi0aBEUCoXR8ZH9YHJDNuv8+fMIDAyEh4eHSa/buXMnfvjhB3z00UeN1uuUlZUZfgjrH1OmTKlzjlarxdixY/HTTz/hhRdewJ9//om//voLhw8fBoAGRw58fHwwdepUfPTRR8jNzcUPP/yAOXPmNBvz7NmzMWzYsHox1PbKK69ApVIhKCgIr732Wr3n09LSMGzYMGRkZGD58uXYt28fjh49ipUrVzYar96NGzcgiiKCg4PrPRcSEgJAl1yZ0/nz5/HBBx9g6dKlkMvldZ5zdXWFIAgmxfOvf/0LwcHBEAQB//nPf5p87/z8fLz66qt46aWXEBUVZXLsTz31FL755hvcuHEDH330EaZPn14vmWrJPc3IyDA81xh9/cqtt95a72t4w4YN9erB9B/7+fkZ9bkplUrMnTsXM2bMQEJCglGv0Rs6dCiOHj2Kw4cP48svv0RkZCTmzJmD/fv3N/m6wYMHY/LkyViyZEmzI4x6b7/9NvLz87n8u4PiUnCySaIo4ujRo4iLizPpdVVVVZgzZw6mTp2KESNG1CmYrM3FxQV79+6tc2znzp148cUXDR+fOXMGJ0+exLp16zB9+nTD8UuXLjUZw5w5czBgwAD4+PggLi4Ot9xyCzZv3tzo+V9//TUOHTqEpKSkJq8bHR2NXbt24eTJk5gwYQLWrFlTZypk06ZNKCsrw08//WQYXQLQ7HUBwNvbGxKJBFlZWfWey8zMBGD8L0djPfXUUxg4cCCmTZtW7zmpVIqwsLAm47m5jmnAgAHYunUrvvnmG8yaNQvjx4/HmDFjGnzvl19+GV5eXnjhhRdaFPvQoUPRrVs3LFy4EL/99hvOnDlT7xxT72lVVRVSUlKaTHBrv+bHH3+s8/+5Mfq6sy5dujR7LgC8++67yMvLw9tvv23U+bXJ5XJDAfnAgQMxcOBA9O3bF08++SSSkpKaHAVavHgxYmNjm01M9fr164cHH3wQ77//Pu644w6TYyXbxpEbskl//vknCgoKTO5lsXz5cly/fh3vvPNOk+dJJBLEx8fXeURHR9c5RxAEAPULmpub5+/Xrx8GDhyIVatWNTtqo1Ao8Pzzz2PevHmIiYlp8twXX3wRQUFBGDduHJ566inMmzevzlRTQ/GKoojPPvusyesCgJubGwYOHIiffvqpzgiPVqvFV199hbCwsEaLQlvixx9/xM6dO+vUJ91s/Pjx+OOPP+qttFm/fj3kcnm9xPfNN9+Eu7s7/vnPf2LixImYPn16vVEMAPjrr7+wZs0arFixwqSpmpvNmTMHH374IUaOHInu3bvXe97Ue7p9+3ZUVlZi4sSJTb7vuHHj4ODggMuXL9f7GtY/atu0aRPc3NyM+kMhLS0N//nPf/DWW2/B39+/2fOb07VrV7zwwgs4ffp0s0XpPXr0wKOPPooPP/wQaWlpRl3/rbfegkqlqldnRPaPIzdkU5RKJX777TfMnTsXUqkUMTExhmkgvZKSElRUVODw4cOIiYmp0/fm448/xjvvvNPgVICpevTogc6dO+Oll16CKIrw8fHBr7/+ih07djT72vXr1+Py5csYMWJEk+f98ssvCAwMxMKFC02K7e2338bOnTvx0EMP4eDBg3B0dMSYMWMgk8nw4IMP4oUXXkBlZSVWr15t9DD/4sWLMWbMGIwcORLPPfccZDIZVq1ahTNnzuDbb781JE96165dM0zFFBUVAdBNgZw7d85wTmVlZYNTgx9//DFmz56Nvn37NhrPK6+8gh9++AG33XYbXnvtNXh5eWHdunXYs2cPVqxY0eAqIr01a9agd+/eeOyxx7Bp06Y6z3366aeYOHFis3UgzXnooYcQERGBrl27NnqOsfd0+/btmDdvHnx9fREUFFTna16r1SIvLw/JycmIiYlBZGQkFi1ahAULFuDKlSsYP348vL29kZOTg7/++gtubm544403cPHiRSxbtgyffPIJXnnllSbvl9769evRp08fzJo1q1X3prbnnnsOH3/8Md544w088MADTa6+ev311/H1119j165dcHNza/baUVFR+Ne//mV0rQ7ZEZHIhly9elUEYPRj165doiiK4tq1a0UAYq9evcSqqqp611u7dq3h2PTp00U3N7d67/3DDz/UuaYoimJycrI4ZswY0cPDQ/T29hbvv/9+MS0tTQQgLly40HDewoULRQBiXl5eg59XQ89HRESIAMRvv/22zrnTp08XIyIimvwcRFEUT548KTo5OYkvvvii4divv/4q9u3bV3R2dhZDQ0PF559/Xty6dWu9z6sx+/btE2+//XbRzc1NdHFxEQcNGiT++uuvdc7R32tjH3FxcYbX7tq1SwQgBgQEiEVFRXWue/M9FUVRPHPmjDhx4kTR09NTdHJyEvv37y9+9dVXdc7RX/Pmz2/r1q2iIAji6tWr69xHZ2dn8cqVK3XOjYiIEKdPn97kvdG//p133jHpeWPuqTH3ccSIEXVes2nTJnHkyJGGexMRESHed9994h9//CGKoii+/fbbYr9+/cSVK1eKWq22zmv1/w+vXr1aJwZBEMSDBw/WOXfEiBH13rshERER4p133tngcytXrhQBiF988YUoijX/z3744Yd6577yyisigHrfoyNGjBB79epV7/y8vDzR09Ozyf83ZH8EUWQbR7IdqampiIqKwq5du5psHGbseUS2QBCEJr+W161bh3Xr1tVbCUXUUbHmhoionRs4cGCT24r4+/s3W5NF1JGw5oZsipOTU7M/6E05j8gW3FxXdrM777yz1TVCRPaE01JERERkVzgtRURERHaFyQ0RERHZlQ5Xc6PVapGZmQkPD496fTmIiIiofRJFEQqFAiEhIc3uadbhkpvMzEyEh4dbOwwiIiJqgfT0dISFhTV5TodLbvSbLKanp3MlDRERkY0oKSlBeHi4UZsld7jkRj8V5enpyeSGiIjIxhhTUsKCYiIiIrIrTG6IiIjIrjC5ISIiIrvC5IaIiIjsCpMbIiIisitMboiIiMiuMLkhIiIiu8LkhoiIiOwKkxsiIiKyK0xuiIiIyK4wuSEiIiK7wuSGiIiI7AqTG7I5oiiiQqWxdhhERNROMbkhm/PM9ycR/9YO5JRUWjsUIiJqh5jckM05dLkAZSoNkjNLrB0KERG1Q0xuyKaIooiCMiUAoKSyysrREBFRe8TkhmxKcUUVqjSi4d9EREQ3Y3JDNiW/VGn4d3E5kxsiIqqPyQ3ZlPxSleHfnJYiIqKGMLkhm1Jn5IbTUkRE1AAmN2RT8hU1yU1JhdqKkRARUXvF5IZsSu1pKY7cEBFRQ5jckE3RLwMHmNwQEVHDmNyQTclTsKCYiIiaxuSGbAoLiomIqDlMbsim1E5uFJVqaLSiFaMhIqL2iMkN2QxRFOskNwBQWskVU0REVBeTG7IZ5SoNKqu0AAAHiQCAU1NERFRfu0huVq1ahaioKDg7OyMuLg779u1r9NwZM2ZAEIR6j169erVhxGQN+lEbF0cp/NydADC5ISKi+qye3GzYsAHz58/HggULkJiYiGHDhmHChAlIS0tr8Pzly5cjKyvL8EhPT4ePjw/uv//+No6c2po+ufHzkEHu4giAK6aIiKg+qyc377//PmbOnInHHnsMPXv2xLJlyxAeHo7Vq1c3eL5cLkdQUJDhcezYMdy4cQP/+Mc/2jhyamv6ZeB+7k7wdHEAwJEbIiKqz6rJjUqlwvHjxzF27Ng6x8eOHYuDBw8adY01a9Zg9OjRiIiIaPB5pVKJkpKSOg+yTfoGfr5uToaRGyY3RER0M6smN/n5+dBoNAgMDKxzPDAwENnZ2c2+PisrC1u3bsVjjz3W6DmLFy+GXC43PMLDw1sdN1lHfvXIjb+HDJ76aSkmN0REdBOrT0sBgCAIdT4WRbHesYasW7cOXl5emDx5cqPnvPzyyyguLjY80tPTWxsuWYmh5sbdCZ7OHLkhIqKGOVjzzf38/CCVSuuN0uTm5tYbzbmZKIr4/PPP8cgjj0AmkzV6npOTE5ycnMwSL1lX7eRGInApOBERNcyqIzcymQxxcXHYsWNHneM7duzA4MGDm3ztnj17cOnSJcycOdOSIVI7UmfkxrBaik38iIioLquO3ADAM888g0ceeQTx8fFISEjAp59+irS0NMyaNQuAblopIyMD69evr/O6NWvWYODAgYiNjbVG2GQFBaW6mhtfdxkqqjQAOHJDRET1WT25mTJlCgoKCrBo0SJkZWUhNjYWW7ZsMax+ysrKqtfzpri4GBs3bsTy5cutETJZSV6tkRtF9YgNkxsiIrqZ1ZMbAHjyySfx5JNPNvjcunXr6h2Ty+UoLy+3cFTUnlRWaQwJjb+7EwqqEx0FkxsiIrpJu1gtRdScgjLdlJSjVICniwPkrlwtRUREDWNyQzZBP1Lj6+YEQRDqNPETRdGaoRERUTvD5IZsQu19pQAY+tyotaKhuJiIiAhoJzU31H4Vlqnw799ScCFHgQFRPhjRzR8Donzg7Cht0zjya+0rBQCuMikcJALUWhHFFVVwlfFLmYiIdPgbgRq150IenvvhJPIUulGT0xnFWLP/KpwcJBgU7YsR3fwxvJs/Ovu7GdVRujVqr5QCYJiaKihTobiiCsFyF4u+PxER2Q4mN1RPZZUGS7aew7qDqQCALgHueHxYFE5cK8KeC3nILqnEngt52HMhDwAQ6uWC4d38cUfvIAzr6m+RmPTTUr7uNd2oPauTm5IKNvIjIqIaTG6ojrOZxZj/XRIu5pYCAKYnRODlO3rC2VGKKbd2giiKuJBTir3Vyc1fVwuRUVSBb/9Kw7d/pWHeqK6YP7qr2Udy9A38/N1rttLw5M7gRETUACY3BADQaEX8d98VvLv9PKo0IvzcnfDO/X0wsntAnfMEQUD3IA90D/LA48OjUa5S48iVQmw9k4Xvj13H8j8voqhchYUTe0EiMV+Ck3/TtBSAOiumiIiI9JjcEDKKKvDs90k4fKUQADAmJhBL7u0NX/fmNxx1lTlgZI8AjOwRgN5hXvi/X87gi0PXcKO8Cu890BeOUvMsyGsoufF01n35ljC5ISKiWpjcdGCiKOKnExl4/dezUFSq4eIoxcKJMZhya3iLppUeGRQBuYsjntmQhM0nM1FSWYXVD8XBRdb6lVX51dNS+qXgAEduiIioYUxuOqjj127gzf8lIym9CADQN9wLy6b0Q5SfW6uue3ffEHg6O2DWV8ex+3weHllzBGtm3GpIRFpCrdHiRnn1pplu9aelSiqZ3BARUQ028etgrt8ox1PfJuJvqw8iKb0IrjIpnh/XHT/OSmh1YqN3W/cAfP3YQHg6O+DYtRuY8skh5JZUtvh6heUqiCIgEQAft7qrpQCO3BARUV1MbjqIUqUa72w7h1Hv7cGvJzMhCMAD8WHY/dxtmD2yi9lqY/TiInyw4YkE+Hs44Vy2Avd9fAhpBS3b7FTfwM/HTQZprSJlw8gNkxsiIqqFyY2d02hFfH80HSPf3Y2Vuy5DqdZiULQPfp0zFEvv64sAT2eLvXfPYE9snDUYnXxckVZYjr99fBDnsktMvk5DxcRAzRYM7HNDRES1sebGRomiCKVaizKlGuUqDcpVGpSp1ChX6v5bodJAUVmF746m42ymLqGI8HXFK3f0xNiYQIt3FNbr5OuKH2clYNrnf+FctgJ///Qwdj93G7xcZc2/uFpDDfwAFhQTEVHDmNy0AY1WRFL6DWw/m4M/UnJQodKgfydvxEV4Iz7SGz2DPZudFlJrtEjOKsHR1Bs4llqIo6k3DL/0m+Ph7IC5t3fFtMERcHJo2z2hACDA0xkb/pmAO1bsQ0ZRBY5fu4FRPQONfr2+gd/NIzdMboiIqCFMbiykskqDA5fysSNZl9DolzLrZZ7Owm+nswAALo5S9A2XIz7CB3GR3rgl3BsOUgGJaUU4mlqIY9cKkZhWhHJVw7tfOztK4CZzgKuTFK6Ouv+6yRzgKpMi2l+3dYIxPWssSe7qiH7hXsgoqsDV/DKTXtvotJRLdZ8brpYiIqJamNyYUVG5CjvP5WL72RzsvZhXJxnxcHbA7T0CMDYmCD5uMpxI043AHL92AyWVahy+UmhoogcAUokAjVasc31PZwfER/ogPtIbt0b6oHuQB9xkDnWKbNsz/WosU5ObmzfN1NOP3JSrNKjSaM1eFE1ERLaJyY2ZXCsow+3v7amTkATLnTE2JhBjYoIwMNqnzi/fhM6+AACtVsSlvFIcv3YDx1Jv4Pi1QqQWlEOjFRHq5YJbI70RH+mDWyN90DXA3axbGrS1yBYmN4YGfjfV3Hg41/TOKa6oqpf8EBFRx8Tkxkw6+bgiWO4MdycHjI0JxNheQegV4tls4a5EIqBboAe6BXrgwQGdAOimYdQaEUFyy61ksoaWjtzkKxoeuZFKBHg4OUChVKOEyQ0REVVjcmMmgiBgy7xhhuXJrWGvv6Sjq5ObrOJKVKg0Rm/LUFDWcHID6Br5KZRqFhUTEZEBixTMyByJjT3zdpMZ6mRSC4wbvdFqxZrVUh71l49zxRQREd2MyQ21KVOnpoorqqCurmOqva+UXs2KKTbyIyIiHSY31KaiTUxu9MvAPZ0dIHOo/+XKkRsiIroZkxtqU6aumDKslPJouA6J+0sREdHNmNxQmzJ1WqqxBn56NftLMbkhIiIdJjfUpvTJTaqJyY1/I8kNp6WIiOhmTG6oTemnpQrKVCgubz4hqRm5aXijTbkrkxsiIqqLyQ21KXcnBwRU189cNWI5eL5CV3PT2N5Yhmkp7i9FRETVmNxQmzNlaqqpBn4Ap6WIiKg+JjfU5vTJzRUjkpu8RvaV0tP3uWFyQ0REekxuqM2ZMnJj2Feq2aXgbOJHREQ6TG6ozRm7HFwUxZqC4ga6EwO6vaUAXc2NttaO7ERE1HExuaE2Vzu5EcXGE5IylQZKtRZAw/tKATUFxaIIKJQcvSEiIiY3ZAWdfF0hCECpUm3oQNwQ/ZSUq0wKV1nDG9g7O0rhVL0tAxv5ERER0MLkRq1W448//sAnn3wChUIBAMjMzERpaalZgyP75OQgRZi3C4Cmp6aa606sxxVTRERUm8nJzbVr19C7d29MmjQJs2fPRl5eHgBg6dKleO6558weINmnSF/91FTjCXFzDfz0PLm/FBER1WJycjNv3jzEx8fjxo0bcHFxMRy/55578Oeff5o1OLJfNbuDlzd6jn4ZeGMN/PTkLmzkR0RENRouZGjC/v37ceDAAchkdf+ajoiIQEZGhtkCI/tWU1Tc+MhNAaeliIioBUweudFqtdBoNPWOX79+HR4eHmYJiuxflL87AONqbvybm5Zy1uXo7HVDRERAC5KbMWPGYNmyZYaPBUFAaWkpFi5ciDvuuMOcsZEdi6quuUktKG+0P41+X6nGGvjpceSGiIhqM3la6oMPPsDIkSMRExODyspKTJ06FRcvXoSfnx++/fZbS8RIdijU2wWOUgEqtRaZxRUI83atd45+5Ma3kQZ+ekxuiIioNpOTm5CQECQlJeG7777D8ePHodVqMXPmTDz00EN1CoyJmiKVCIjwdcOl3FJczS9rMrkxerUUC4qJiAgtSG4AwMXFBf/4xz/wj3/8w9zxUAcSWZ3cpOaXYVhX/3rPF5QaNy3lyZEbIiKqxeSamy1btjR4/OLFixg6dGirA6KOI9q/8d3BK6s0hu0UuFqKiIhMYXJyM2XKFHz//fd1jn3wwQfo168fevbsabbAyP41tYGmfkpKJpUYVkM1Rr+/FJv4ERER0IJpqR9//BH3338/SkpKcNttt2HGjBlIT0/Hxo0bMX78eEvESHZK36U4tcHkRt/ATwZBEJq8Ts3IDZeCExFRC5KbcePGYcuWLZg4cSKUSiWmTp2KLVu2wNPT0xLxkR3TT0ul36iASq2FzKFmINHYBn4A4Omi73NTBVEUm02GiIjIvrVo48yhQ4di165d8PDwQGBgIBMbapEADye4yqTQaEWk36i7DYOxK6WAmpEblUYLpVpr/kCJiMimmDxyc++99xr+HRwcjCVLluDAgQPw8fEBAPz000/mi47smiAIiPR1Q3JWCVLzy9C5umsxUDMtZczIjbuTAyQCoBV1RcXOjlKLxUxERO2fycmNXC43/Lt///7o37+/WQOijiXKX5fc3FxUnKeobuBnRHIjCAI8XRxRVF6F4ooqBHo6WyRWIiKyDSYnN2vXrrVEHNRB6XcHv3k5uCnTUoBuaqqovIorpoiIqGVN/AAgNzcX58+fhyAI6NatGwICAswZF3UQja2Y0jfw82+mgZ8ee90QEZGeyQXFJSUleOSRRxAaGooRI0Zg+PDhCA0NxcMPP4zi4mJLxEh2LMq/4V43+SaslgJqet0wuSEiIpOTm8ceewxHjhzB//73PxQVFaG4uBj/+9//cOzYMTz++OOWiJHsmH5aKqu4EhUqjeG4qcmNfuSG01JERGTytNRvv/2Gbdu21dlqYdy4cfjss8/YxI9M5uUqg5errl4mtaAMPYM9UaXR4ka5LknxNbLmxpON/IiIqJrJIze+vr51VkzpyeVyeHt7myUo6lhu3obhRpmu3kYiAN6uxiY3ujyd01JERGRycvPqq6/imWeeQVZWluFYdnY2nn/+ebz22mtmDY46hpuTm7zqKSkfNydIJcZ1GzZMS1UyuSEi6uhMnpZavXo1Ll26hIiICHTq1AkAkJaWBicnJ+Tl5eGTTz4xnHvixAnzRUp2K8q3bnJT08DPuFEbgKuliIiohsnJzeTJky0QBnVkN6+YyleYVkwMcLUUERHVMDm5WbhwoSXioA7s5mkpUxv4AVwtRURENVrcxO/48eNISUmBIAiIiYnhNgzUYvpGfoVlKhSXV6GgzPh9pfSY3BARkZ7JyU1ubi7+/ve/Y/fu3fDy8oIoiiguLsbIkSPx3Xffwd/f3xJxkh1zc3JAoKcTckqUuFpQVjMtZWR3YqD2UnAmN0REHZ3Jq6WeeuoplJSU4OzZsygsLMSNGzdw5swZlJSUYO7cuZaIkTqAmqmpUsNqqZaM3JSpNFBrtOYPkIiIbIbJyc3vv/+O1atXo2fPnoZjMTExWLlyJbZu3WrW4KjjqEluyg2rpYxt4AcAHs41g5AllWzkR0TUkZmc3Gi1Wjg6OtY77ujoCK2WfzFTy9QuKi6oHrnxN2HkxlEqgZtMCoBTU0REHZ3Jyc3tt9+OefPmITMz03AsIyMDTz/9NEaNGmXW4KjjiPJzBwBcySttUUExwKJiIiLSMTm5+eijj6BQKBAZGYnOnTujS5cuiIqKgkKhwIcffmiJGKkDiPJzBQCcz1ZAoxUBAD5uxk9LASwqJiIiHZNXS4WHh+PEiRPYsWMHzp07B1EUERMTg9GjR1siPuogwn1cIREAdXViI3dxhMzBtNzbk1swEBERWtHnZsyYMRgzZow5Y6EOzMlBijBvV6QVlgMwrYGfHrdgICIiwMhpqR07dtT5+LfffsPw4cPh5+cHf39/jBgxAlu2bLFIgNRxRFYXFQOm19sA3IKBiIh0mk1uRFHEXXfdhdTUVADAf//7X9xzzz3o3r073nvvPbz77rvo2rUr7rnnHqxdu7ZFQaxatQpRUVFwdnZGXFwc9u3b1+T5SqUSCxYsQEREBJycnNC5c2d8/vnnLXpvaj+iayc3JjTw06spKOZScCKijqzZaSlBEODl5WVY5v3222/jgw8+wOzZsw3nTJ8+Hf3798eSJUvwj3/8w6QANmzYgPnz52PVqlUYMmQIPvnkE0yYMAHJycmGXcdv9sADDyAnJwdr1qxBly5dkJubC7Wav9BsXVTt5MbEYmKA01JERKRj1LRUUFAQMjIyAADXr1/HuHHj6p0zbtw4XLt2zeQA3n//fcycOROPPfYYevbsiWXLliE8PByrV69u8Pzff/8de/bswZYtWzB69GhERkZiwIABGDx4sMnvTe1Lq6elXHS5OpeCExF1bEYlN2PHjsXy5csBAF26dKlXgwPo6nLCwsJMenOVSoXjx49j7Nix9d7v4MGDDb5m8+bNiI+Px9KlSxEaGopu3brhueeeQ0VFRYPnK5VKlJSU1HlQ+2S2aSmuliIi6tCMWi314osv4pZbbsG0adMwcuRIzJ8/H0lJSRg6dCgEQcD+/fuxbt06vPvuuya9eX5+PjQaDQIDA+scDwwMRHZ2doOvuXLlCvbv3w9nZ2f8/PPPyM/Px5NPPonCwsIG624WL16MN954w6S4yDpCvFwgk0qg0mhbNHLDaSkiIgKMHLnx8/PD8ePHIZPJ8P3330OtVuOzzz7D9OnTMXfuXJw6dQpffvkl5syZ06IgBEGo87EoivWO6Wm1WgiCgK+//hoDBgzAHXfcgffffx/r1q1rcPTm5ZdfRnFxseGRnp7eohjJ8qQSAbGhngCAzv5uzZxdH5v4ERERYEKfG39/f/z3v/8165v7+flBKpXWG6XJzc2tN5qjFxwcjNDQUMjlcsOxnj17QhRFXL9+HV27dq1zvpOTE5ycTB8FIOv45JF4ZBVXINrf3eTXcvsFIiICWrD9gjnJZDLExcXVq+HZsWNHowXCQ4YMQWZmJkpLSw3HLly4AIlEYnLND7U//h5O6BPm1aLX1tTcqCGKohmjIiIiW2Jyh+KoqKhGp4wAXU2MKZ555hk88sgjiI+PR0JCAj799FOkpaVh1qxZAHTTShkZGVi/fj0AYOrUqXjzzTfxj3/8A2+88Qby8/Px/PPP49FHH4WLi4upnw7ZEX0TP41WRKlSDQ/n+rvXExGR/TM5uZk/f75ZA5gyZQoKCgqwaNEiZGVlITY2Flu2bEFERAQAICsrC2lpaYbz3d3dsWPHDjz11FOIj4+Hr68vHnjgAbz11ltmjYtsj7OjxFCQXFLJ5IaIqKMSxFaO3+/atQuJiYno3bu3Tew1VVJSArlcjuLiYnh6elo7HDKz+Ld2IL9UhS1zhyEmhP9/iYjshSm/v1tVc7Nq1SqMGTMGq1evxl133YUPPvigNZcjajWumCIiolYlNx9//DFWrFiBixcv4ocffsCqVavMFRdRi7CRHxERtSq5SU9Px+jRowEAo0aNqlMbQ2QN3BmciIhaldyo1Wo4Oup+mTg4OHDzSrI69rohIiKTV0vde++9hn9XVlZi1qxZcHNzM+waTmRNTG6IiMjk5KZ2Z+CHH364znPTpk1rfUREraDfGZzTUkREHZfJyc3atWstEQeRWXDzTCIiavX2C1VVVUhMTMSNGzfMEQ9Rq9TegoGIiDomk5Ob48ePIyEhAXfeeScuXbqEPn36IC4uDmFhYdi+fbslYiQyGldLERGRycnN3Llz4eHhAXd3d4wdOxYjRoxAeno6Zs2ahQULFlgiRiKjcVqKiIhMrrk5efIkjh8/joiICLi7u2POnDkIDQ3FnDlz8PHHH1siRiKjeXK1FBFRh2fyyE15eTl8fHzg7OwMFxcXuLq6AgBcXV1RWVlp9gCJTMGRGyIiMnnkBgA+++wzuLu7Q61WY926dfDz84NCoTB3bEQm04/cKNVaVFZp4OwotXJERETU1kxObjp16oTPPvsMABAUFIQvv/yyznNE1uTh5ABBAERRt78Ukxsioo7H5OQmNTXVAmEQmYdEIsDDyQEllWqUVFQhwMPZ2iEREVEba3WfG6L2Ru6qr7thrxsioo6IyQ3ZHX2vG66YIiLqmJjckN3hiikioo6NyQ3ZnZotGJjcEBF1RExuyO4YtmAoZ3JDRNQRmbxa6tSpU00+36dPnxYHQ2QONQXFTG6IiDoik5Obfv36QRAEAIAoigAAQRAgiiIEQYBGozFvhEQm4rQUEVHHZtS0VEREBD788EMAwJAhQ+Dm5oY333wTV65cwdWrV+v8l8jaPJ11OTtHboiIOiajkpvdu3fjueeeQ2lpKfbt24d169Zh3bp1eOCBB5Ceno6IiAjDg8jaPLlaioioQzMquQkICIBWq4VarWuKdu+99yI5ORlTp07F5MmTce+99+LSpUsWDZTIWIZpKTbxIyLqkIxKbuLi4jBnzhx4eXkZjjk4OGD+/Pm4dOkSoqKicMstt2D+/PkWCpPIeBy5ISLq2IwqKD569Cg8PDwAAN7e3oaC4tqUSiU+/PBDLFu2zKwBEpmqZuSGyQ0RUUdkVHKjT2wAMHmhdk+f3CiUami0IqSS+sk4ERHZL5OXgk+fPt0ScRCZjb6JHwAoKqvg5SqzYjRERNTWTE5uAECj0WDTpk1ISUmBIAiIiYnB3XffDalUau74iEwmc5DAxVGKiioNiiuY3BARdTQmJzeXLl3CHXfcgYyMDHTv3h2iKOLChQsIDw/Hb7/9hs6dO1siTiKTyF0cUVGl4YopIqIOyOS9pebOnYvOnTsjPT0dJ06cQGJiItLS0hAVFYW5c+daIkYik+nrbm6Uq6wcCRERtTWTR2727NmDw4cPw8fHx3DM19cXS5YswZAhQ8waHFFLBcqdcT5HgeziSmuHQkREbczkkRsnJycoFIp6x0tLSyGTsbaB2odQL2cAQEZRhZUjISKitmZycnPXXXfhn//8J44cOQJRFCGKIg4fPoxZs2bh7rvvtkSMRCYLkbsAADKZ3BARdTgmJzcrVqxA586dkZCQAGdnZzg7O2PIkCHo0qULli9fbokYiUwW4lWd3BQzuSEi6mhMrrnx8vLCL7/8gosXL+LcuXMQRRExMTHo0qWLJeIjapFQb/3IDWtuiIg6mhb1uQGArl27omvXruaMhchsQqtHbjKKKiCKYoNbhhARkX0yeVrqxo0bePnll/HOO++gqqoKjz76KORyOQYNGsSdwandCPR0hiAAKrUWBWVcDk5E1JGYnNw89thj+Oqrr/DZZ59h/PjxuHDhAlatWgUPDw/2uaF2Q+YgQYCHEwAg4wbrboiIOhKTp6V2796NLVu2ICIiAiEhITh06BAGDhyIvn37Yvjw4ZaIkahFQrxckFOiRGZRBfqGe1k7HCIiaiMtmpaKiopCUFAQ3Nzc4O/vDwDw9/dHcXGx2QMkaqmQWnU3RETUcbSooDg5ORnZ2dkQRRHnzp1DaWkp8vPzzR0bUavoi4q5YoqIqGNpUXIzatQoiKIIQNfUTxAErkihdidErutSzEZ+REQdi8nJzdWrVy0RB5HZsZEfEVHHZHJyExERYYk4iMyuppEfkxsioo6kRdNSly9fxrJly5CSkgJBENCzZ0/MmzcPnTt3Nnd8RC2mr7nJL1WhskoDZ0eplSMiIqK2YPJqqW3btiEmJgZ//fUX+vTpg9jYWBw5cgS9evXCjh07LBEjUYvIXRzhKtMlNFnFLComIuooTB65eemll/D0009jyZIl9Y6/+OKLGDNmjNmCI2oNQRAQ4uWCS7mlyCyqQJSfm7VDIiKiNmDyyE1KSgpmzpxZ7/ijjz6K5ORkswRFZC7sdUNE1PGYnNz4+/sjKSmp3vGkpCQEBASYIyYiswn10i0H5xYMREQdh8nTUo8//jj++c9/4sqVKxg8eDAEQcD+/fvx9ttv49lnn7VEjEQtFiLniikioo7G5OTmtddeg4eHB9577z28/PLLAICQkBC8/vrr3DiT2h32uiEi6nhMTm4EQcDTTz+Np59+GgqFAgDg4eFh9sCIzCGEWzAQEXU4Jtfc3H777SgqKgKgS2qY2FB7FuZdU1Cs3zKEiIjsm8nJze7du6FSqSwRC5HZBXo6QxAAlVqLgjJ+3RIRdQQmJzcAuEEm2QyZgwQBHk4AWFRMRNRRtGj7hXvuuQcymazB53bu3NmqgIjMLcTLBTklSmQWVaBPmJe1wyEiIgtrUXKTkJAAd3d3c8dCZBEhXi5ITCtCBouKiYg6hBatlnr++efZsI9sRqgXe90QEXUkJtfccMUJ2ZoQObsUExF1JCYnNwsXLuSUFNkUNvIjIupYTE5upk2bhoyMjHrHL168iNTUVHPERGRWIZyWIiLqUExObmbMmIGDBw/WO37kyBHMmDHDHDERmZW+kV9+qQqVVRorR0NERJZmcnKTmJiIIUOG1Ds+aNCgBncLJ7I2uYsjXGVSAEBWMVdMERHZO5OTG0EQDHtK1VZcXAyNhn8VU/sjCAKnpoiIOhCTk5thw4Zh8eLFdRIZjUaDxYsXY+jQoWYNjshc9MlNBpMbIiK7Z3Kfm6VLl2L48OHo3r07hg0bBgDYt28fSkpK2J2Y2q1QL91ycI7cEBHZP5NHbmJiYnDq1Ck88MADyM3NhUKhwLRp03Du3DnExsZaIkaiVguRc1qKiKijaNH2CyEhIfjPf/5j7liILKam5oYFxURE9q5Fu4Lv27cPDz/8MAYPHmzoefPll19i//79LQpi1apViIqKgrOzM+Li4rBv375Gz929ezcEQaj3OHfuXIvemzoGFhQTEXUcJic3GzduxLhx4+Di4oITJ05AqVQCABQKRYtGczZs2ID58+djwYIFSExMxLBhwzBhwgSkpaU1+brz588jKyvL8OjatavJ700dR2itgmJuIUJEZN9MTm7eeustfPzxx/jss8/g6OhoOD548GCcOHHC5ADef/99zJw5E4899hh69uyJZcuWITw8HKtXr27ydQEBAQgKCjI8pFKpye9NHUeQ3BmCACjVWhSUqawdDhERWZDJyc358+cxfPjwesc9PT1RVFRk0rVUKhWOHz+OsWPH1jk+duzYBrsg19a/f38EBwdj1KhR2LVrl0nvSx2PzEGCAA8nAJyaIiKydyYnN8HBwbh06VK94/v370d0dLRJ18rPz4dGo0FgYGCd44GBgcjOzm70/T/99FNs3LgRP/30E7p3745Ro0Zh7969DZ6vVCpRUlJS50EdE+tuiIg6BpNXSz3xxBOYN28ePv/8cwiCgMzMTBw6dAjPPfcc/u///q9FQQiCUOdjURTrHdPr3r07unfvbvg4ISEB6enpePfddxscUVq8eDHeeOONFsVF9iXEywWJaUXI4IopIiK7ZnJy88ILL6C4uBgjR45EZWUlhg8fDicnJzz33HOYM2eOSdfy8/ODVCqtN0qTm5tbbzSnKYMGDcJXX33V4HMvv/wynnnmGcPHJSUlCA8PNylOsg+hHLkhIuoQWtTn5t///jcWLFiA5ORkaLVaxMTEwN3d3eTryGQyxMXFYceOHbjnnnsMx3fs2IFJkyYZfZ3ExEQEBwc3+JyTkxOcnJxMjo3sT4icXYqJiDoCk5ObRx99FMuXL4eHhwfi4+NbHcAzzzyDRx55BPHx8UhISMCnn36KtLQ0zJo1C4Bu5CUjIwPr168HACxbtgyRkZHo1asXVCoVvvrqK2zcuBEbN25sdSxk31hzQ0TUMZic3HzxxRdYsmQJPDw8zBLAlClTUFBQgEWLFiErKwuxsbHYsmULIiIiAABZWVl1et6oVCo899xzyMjIgIuLC3r16oXffvsNd9xxh1niIftVs3kma26IiOyZIJrY0UwikSAnJwf+/v6WismiSkpKIJfLUVxcDE9PT2uHQ23oRpkK/d/cAQA49+Z4ODuyNxIRka0w5fd3i2pu5s6dCxcXlwaf+/zzz1tySSKL83J1hKtMinKVBlnFlYjyc7N2SEREZAEt2ltKFMVGH0TtlSAIrLshIuoATB65EQQBK1asQEBAgCXiIbKoEC8XXMotRQaTGyIiu2XyyA1HZ8iWhXpxOTgRkb0zObmZPn16o/U2RO1diJzTUkRE9s7kaam1a9daIg6iNlFTc8Pl4ERE9qpFBcVEtooFxURE9o/JDXUooYZGfhWsHyMislNMbqhDCZI7QxAApVqLwjKVtcMhIiILYHJDHYrMQYIAD91Gqqy7ISKyTy3qUAwAycnJSEtLg0pV96/fu+++u9VBEVlSiJcLckqUyCiqQO8wubXDISIiMzM5ubly5QruuecenD59GoIgGOoWBEEAAGg0GvNGSGRmIV4uSEwrYiM/IiI7ZfK01Lx58xAVFYWcnBy4urri7Nmz2Lt3L+Lj47F7924LhEhkXqFcMUVEZNdMHrk5dOgQdu7cCX9/f0gkEkgkEgwdOhSLFy/G3LlzkZiYaIk4icwmRM4uxURE9szkkRuNRgN3d3cAgJ+fHzIzMwEAEREROH/+vHmjI7IA9rohIrJvJo/cxMbG4tSpU4iOjsbAgQOxdOlSyGQyfPrpp4iOjrZEjERmFWLodcPVUkRE9sjk5ObVV19FWVkZAOCtt97CXXfdhWHDhsHX1xcbNmwwe4BE5qavuckvVaKySgNnR6mVIyIiInMyObkZN26c4d/R0dFITk5GYWEhvL29DSumiNozL1dHuMqkKFdpkF1ciUg/N2uHREREZmSWJn4+Pj5MbMhmCILAuhsiIjtm8sjNvffe2+TzP/30U4uDIWorIV4uuJRbyl43RER2yOSRG7lcbnj89ttvkEgkdY4R2YJQL/1ycBYVExHZG5NHbtauXWv4948//oilS5dylRTZnBA5p6WIiOwVN86kDqlmOTiTGyIie8PkhjokFhQTEdkvk6elVqxYYfi3Wq3GunXr4OfnZzg2d+5c80RGZEGhtUZuRFHkaj8iIjsiiPptvY0UFRXV+MUEAVeuXGl1UJZUUlICuVyO4uJieHp6WjscshKVWovur22FKALHXx0NX3cna4dERERNMOX3t8kjN1evXm1xYETthcxBggAPJ+SUKPHCj6cQ5eeGQE9nBHg6IcBD999AT2e4O5n8LUJE1KH9d98VxEV4o1+4l9VGxfmTmzqsnsGeyCnJw5/nchs9x1UmRbdAD6yZHs/RHSKiZqQXluPfW1IgisC+F0Yi3MfVKnEwuaEOa/nf+2PvhTzklFQiV6HU/bdEiRxFJfJKlFAo1ShXaZCUXoQdyTn4+4BO1g6ZiKhd++rwNYgiMKyrn9USG4DJDXVgchdHTOwb0ujz5So13t56Dl8cuoZTGcX4exvGRkRkayqrNNhwLB0AMD0h0qqxcCk4USNcZQ4YGO0LADh1vci6wRARtYIoijBx/ZDJNp/MRFF5FUK9XDCyR4BF36s5TG6ImtAnTLelyPlsBSqrNFaOhojIdCWVVUhYvBOPrjtqsfcQRRHrD6UCAB4eFAGpxLrtNVo8LVVeXo60tDSoVKo6x/v06dPqoIjai1AvF/i4yVBYpsK5bAX6hXtZOyQiIpOcuHYD2SWVyC6phKKyCh7OjmZ/j8T0IpzJKIHMQYIpt4ab/fqmMjm5ycvLwz/+8Q9s3bq1wec1Gv51S/ZDEAT0CZNj9/k8nL5exOSGiGzOhRyF4d/nsxWIj/Qx+3t8eegaAGBinxD4uMnMfn1TmTwtNX/+fNy4cQOHDx+Gi4sLfv/9d3zxxRfo2rUrNm/ebIkYiayqT6huaurk9WIrR0JEZLpz2TXJTUpWidmvn1+qxG+nsgAA0wdHmP36LWHyyM3OnTvxyy+/4NZbb4VEIkFERATGjBkDT09PLF68GHfeeacl4iSymt5hXgCA00xuiMgGna+V3CRnKZo4s2U2HE2HSqNF33Av9Kn+eWltJo/clJWVISBAVwXt4+ODvLw8AEDv3r1x4sQJ80ZH1A7oi4ov5ipQrlJbORoiIuNptCIu5pYaPjb3yI1ao8XXh3VTUtMGtY9RG6AFyU337t1x/vx5AEC/fv3wySefICMjAx9//DGCg4PNHiCRtQV6OiPQ0wlaETibaf4hXSIiS0ktKINKrTV8fD5bAY3WfEvC/0jJRWZxJXzcZLizT/vJAVpUc5OVpZtbW7hwIX7//Xd06tQJK1aswH/+8x+zB0jUHuiHWk+mF1k1DiIiU+inpHqFeMLJQYKKKg2uFZSZ7fpfHk4FAEy5NRzOjlKzXbe1TK65eeihhwz/7t+/P1JTU3Hu3Dl06tQJfn5+Zg2OqL3oEyrHjuQcnM5g3Q0R2Q59chMT7AmpRMCp68VIyVIg2t+91de+lKvAgUsFkAjAQwPb1/Y0rW7i5+rqiltuuQV+fn7Izs42R0xE7U6f6iXgp1hUTEQ2RJ/cdA/yQM8gTwDmq7vRL/8e1TMQYd7W20eqISYnNwsWLGjw+JdffolevXq1OiCi9qh39XLwq/llKK6osnI0RETGOV/d46ZHkCd6BnsAME9yU6pUY+OJDADAtIT2U0isZ3Jy89VXX+Gpp54yfJyTk4O7774bTz/9NJYvX27W4IjaCx83GcJ9XAAAZzg1RUQ2oLJKg9Tq+ppuQe7oGWy+kZufEzNQqlQj2t8NQzq3v5IUk5Obffv2Yfv27Zg+fTq+/PJLxMTEQBAEnDlzBg8//LAlYiRqF/qEegHg1BQR2YaLOaUQRd0fZ/7uTuhRndxkFleiqFzVzKsbJ4oi1h9MBQA8MigCEivvI9UQk5ObTp06Ye/evUhKSsKMGTPw9ttv45dffkFQUJAl4iNqN/T9brhDOBHZgnPZuhGa7oEeEAQBchdHhHrpRqBTWtHM7/CVQlzMLYWrTIq/xYWZJVZza1FBcWBgIPbs2YOBAwdiw4YNqKioMHdcRO1Ob0Nyw5EbImr/9HtKdQ/yMBwzx9SUfvfve/qHwtMCm3Cag8lLwb29vSEIuiGoqqoqQ8diR0fdJ1hYWGjeCInaCX1RcUZRBQpKlfB1d7JyREREjTuXXT+5iQn2wB8pOS1ObrKKK7A9OQcAMC0hstUxWorJyc2yZcssEAZR++fh7IhofzdcySvDqYxijOweYO2QiIgadb6B5MYwcpPdsuTm2yNp0GhFDIjyqXPd9sbk5Gb69OmWiIPIJvQN89IlN+lMboiocRUqDRSVVXCUSuDoIIGjVIBMKjHMfFjajTIVchVKAEC3wPrJzYWcUqg1WjhIja9OUam1+OavdADA9HY8agO0ILkBAKVSia+//hrJyckQBAG9evXCgw8+CCcnDtOTfesdKsfPiRk4nVFk7VCIqJ3KLKrA2A/2olRZf6NdR6mgS3iqH75uMoR4OSPEywWh3i4I9XJBSPUj0MPJpOSjNn1/mzBvF7g71fyq7+TjCjeZFGUqDa7kl9VJfJpzLLUQ+aVK+LnLMLZXYIviaivNJjcajQZRUVE4fvw4/P39kZycjPHjx6O0tBR9+/YFAKxZswYLFy7Etm3b0KNHD4sHTWQtfcN1dTcnrxdDFMU2+yuMiGzHjuScBhMbAKjSiKjSaABoAAD5pUpDInIziQAEeTrjoUERmD2yi0kx6Keketw0dSSRCOge5IETaUVIySoxKbnZcyEPADCiWwAcW5h0tZVmkxupVIqSkhIoFAr4+/tj3rx5iI+Px/r16+HurtubQqFQYNq0aZg3bx62bdtm8aCJrCUmWA6pRECeQomcEiWC5M7WDomI2pmDl/MBAM+P645ZIzqjSqOFSqNFlVqLKo0IlVr3sUqtRX6pEplFFcgsqkBGUWX1fyuQVVyBKo2IzOJKLP/zIh4dEgUXmfEbU+oTpoaSl57BnjiRVoTkrBJM6hdq9DV3n69Obrr7G/0aazFqWsrPzw/l5eUAgIMHD+Kvv/4yJDYA4OHhgUWLFiEhIcEyURK1Ey4yKboGuONctgInrxchSM7+TkRUQ6MVcehyAQBgcGdfSCUCpBKpyTtma7Ui8kuVmLzyADKLK3H4aoFJdX4NFRPr1SwHN77XTVZxBc7nKCARgGFd2l9H4psZNa7Uv39/bN26FQDg5eWFoqKieucUFxdDJpOZNTii9kjfzO80+90Q0U3OZhajpFINDycHQ/uIlpBIBAR4OhtGSfZWTwkZQxRFXMiu2VPqZi3pdbOnetSmb7gXvN3a/+96o5Kb2bNn46233sLOnTsxefJkPP744zh06BBEUYQoijh8+DBmzZqFO++809LxElldnzAvAMBJdiomopscrB61GRjt0+Ji4NqGdzU9ucksroRCqYaDRECUn1u953sEeUAQgDyFEvmlSqOuWVNv0/6npAAjp6Vuu+02rFq1Cvfddx9cXFyQlZWFoUOHwsFB93K1Wo3x48dz40zqEAwjNxksKiaiug5c0tXbDDbTZpKDu/hBKhFwOa8M12+UI8zbtdnXnK/uYdPZ3x0yh/oJlpuTAyJ8XJFaUI6UrBIM69p0wlKl0WL/Rd3ndZuNtMAwein4Qw89hMmTJ2Pfvn3Iy8uDVqsFoOtY3KNHD3Tr1s1iQRK1J92DPCCTSlBUXoX0wgp08m3+hw0R2T+lWoOjqbou/UPMVJcid3FEv3AvHL92A3sv5GPqwE7NvkbfmbhbE032egZ7Gp3cJKYVQaFUw9vVsVVTbW3JpD43bm5uGD9+vKViIbIJTg5S9Aj2wKnrxTiVUcTkhogA6JKAyiot/Nxl6Bbo3vwLjDSim391cpNnVHJzoZFl4LX1DPbE1jPZOGdEUfGeC7kAgOHd/CFthzuAN8TkJn4rVqxo8vm5c+e2OBgiW9EnTK5Lbq4X464+IdYOh4jaAX29TUJnP7NOVw/v5o/3d1zAgcv5RnUVNuwp1UQPG31RcbIRRcWGJeA2Um8DtCC5mT9/PlxdXREQEABRFOs8JwgCkxvqEPqEegFIwykWFRNRtYPV9TZDOvua9bq9Q+XwcnVEUXkVktKLEB/p0+i5VRotLueVAmh4Gbhez2Ddc5fzSqFSaxuszQGAXEUlzmbqEqDmpq/aE5NLuV955RVIJBKMHj0ahw8fxtWrVw2PK1euWCJGonanT3Wn4jMZJdBqxWbOJiJ7V6ZUIym9CID56m30pBIBQ6uvuaeZVVOp+WWo0ohwk0kR6uXS6HmhXi7wdHZAlUbEpdzSRs/bd0GXsPUOlcPfw3a2WDI5uXnrrbeQkpIClUqF7t2749///jeUSuOWkhHZiy7+7nB2lKBUqcaV/DJrh0NEVvZXaiHUWhFh3i4I9zF/HZ5+Sqi5JeG1i4klTdTHCIKAHkb0u9ltY0vA9Vq0CD80NBTr1q3Dzp078eeff6JLly5Yv369uWMjarccpBLEhuhGbzg1RUQ1U1KW6d47vDq5OJVRjMIyVaPnnTei3kYvppnkRqMVse+iLrm5zQa2XKjN5OTm1KlThoeDgwOWLVuGf/7zn5gzZw7i4uIsESNRu9Q7TJ/csFMxUUd34FL1lgtdzFtvoxfo6YweQR4QRWB/dSLVEP2eUk3V2+jp625SshtObk5eL0JReRU8nB3QL9zL9KCtyOSC4n79+kEQBEMxce1/JyUlmTU4ovasb3WnYmNGbrRaEYpKNeSujpYNioja3I0ylWHVUYKZi4lrG97NH+eyFdhzPg939214lWZTe0rdrPYeUw01JNVvuTCsq59Zui23JZOTm6tXr1oiDiKbox+5OZtZ0uTyzAs5Cjy9IQkpWSXYNHuIYfsGIrIPh67oRm26BbojwMPZYu8zops/Pt17Bfsu5jWYjJQp1Ugr1G1ybcy0VLdAD0gEoLBMhVyFEoGedWPXFy/f1s02uhLXZnJyExERYYk4iGxOlK8bPJwcoFCqcTG31PBXkJ5WK2LtwVS8/fs5qNS6jt47z+UyuSGyM+becqEx8ZHecHGUIlehxLlsRb2fORerVz35uTvB1735lU3OjlJE+7vjUm4pkrNK6iQ3hWUqw/55w22smBhoQXKzefPmJp+/++67WxwMkS2RSATEhspx6EoBTl0vqvODJqu4As/9cNIwDx/o6YScEqVhqSgR2Q998z5zLwG/mZODFIOifbDrfB72Xsirl9zo95RqqjPxzXoGe+JSbilSskowsta+UbrRId21guSWG42yFJOTm8mTJzf6nEQigVqtbk08RDalT7g+uSnGlFt1x35JysBrm86gpFINF0cpFtzZE71CPHHPqoM4mV7EzTaJaqms0sDJQWKz3xOZRRW4ml8GiQAMiGq8uZ65DO/mr0tuLubhiRGd6zxnWAZuxJSUXs9gD/x6Uld3U5u+3maEja2S0jM5udFvmHmzyspKuLpyjx3qWHSdinUrporLq/DaL2ew+WQmAKBvuBc+eKAvov3doVRrIJNKcKO8CmmF5YjwdbNi1ETtQ0pWCe7+aD/u6R+Kpff1tXY4LaIftekd5gW5i+UXDOj7zRy9egPlKjVcZTW/xi/kNL+n1M16NrAcXKsVsfeibfa30TNb+bMgCDabeRO1VJ/qouJz2SUYv3wvNp/MhFQiYP7orvhxVgKi/XWb5zk5SBETovshwqkpIp3fz2SjSiPi+2PXsf1strXDQa6iEveuOoAPdlww+jWW2nKhMVF+bgjzdoFKo8Xh6kJmPVNWSunpe91cyStFZZUGgG6/qfxSFdxkUsRHWH40yhLaxdquVatWISoqCs7OzoiLi8O+ffuMet2BAwfg4OCAfv36WTZAokaEebvA29URVRoRWcWViPJzw8Z/Dcb80d3geNPqKX2fiMS0orYPlKgdOpF2w/Dv1345g5LKKitGA3z45yWcSCvC8j8vNtsJGABEUTSM3Fi6mFhPEARDge/eCzX9bvJLlcgvVUEQgK4m7Ege4OEEHzcZtGLNyM/u87pdwAd38Wt0z6n2zuSoo6KiEB0dXe/Ro0ePFgWwYcMGzJ8/HwsWLEBiYiKGDRuGCRMmIC0trcnXFRcXY9q0aRg1alSL3pfIHARBMAzbPjyoE36bO7TRZlf9O+mOc+SGSNf9Vp/oe7k6IqdEiaW/n7NaPBlFFdhwNN3w8YsbTzWbbF3JL0N2SSVkDhLER3pbOkSD4V3rb8VwoXrUppOPa52pquYIglDTzK96asqwBNxG622AFu4K3pCqqiq8+OKLJgfw/vvvY+bMmXjssccAAMuWLcO2bduwevVqLF68uNHXPfHEE5g6dSqkUik2bdpk8vsSmcs79/fFC+N7IKSJTeqAmpGb5MwSKNUaODlI2yA6ovbpfLYCpUo13J0c8NGDt+DhNUfw1eE0TOoXilub2PXaUlbuugSVRotbI72Rp1AitaAcb/0vuclaIP2UVFwnbzg7tt338+AuvnCQCLiSX4b0wnKE+7i2qJhYr2eQJw5cKkBKlgLFFVU4UZ10DrehXcBvZnJyM2/evAaPV1ZWmpzcqFQqHD9+HC+99FKd42PHjsXBgwcbfd3atWtx+fJlfPXVV3jrrbeafA+lUllnY8+SksY3CCNqCUeppNnEBtD9ReXjJkNhmQopWQqba2dOZE7Hq6ek+nfywtCufpgSH44Nx9Lx0sZT2DJvWJsm/+mF5fjhmG7U5vlxPSAIwAOfHML3x65jfGwQbu8R2ODrapaAt029jZ6nsyNu6eSNv1ILsedCHh4eFGGotzGlmFhPX1ScnFWCA5fyodGK6OzvZpENQNuKWQuKTZWfnw+NRoPAwLpfOIGBgcjObri47OLFi3jppZfw9ddfw8Gh+dxs8eLFkMvlhkd4eLjJcRKZgyAI6FtdgJxUq9aAqCM6cU33PXBLJ910zit39ISfuxMu55Vh5a7LbRrLyl2XUKURMbSLHwZE+eDWSB/MHBIFAHhp42kUl9efntJqRUNn4oQ2qrepbXg33Xvqp6ZM2VPqZrVXTOnrbW7rbntdiWszeeRmxYoVDR5vTX+bmxOjxvqAaDQaTJ06FW+88Qa6detm1LVffvllPPPMM4aPS0pKmOCQ1fQL98au83msu7mJKIpQqrVtOrRP1nW8OrmJi9AlN3JXRyya1AtPfn0Cq3dfwp29g1v0i9pUaQXl+PH4dQDA02O6Go4/N647dp7LxZX8Mrzx61m8P6VfndclZ5WgqLwK7k4Ohj9a2tLwbv54d/sFHLxcAKVaYygGNmbbhZt1CXCHo1SAolKN305lAbDdJeB6Jic3H3zwQaPPderUyaRr+fn5QSqV1hulyc3NrTeaAwAKhQLHjh1DYmIi5syZA0DXd0cURTg4OGD79u24/fbb67zGyckJTk7Nt6Emagt9w6tHblqY3Gw7m41vjqRh6X196u0DY8u+OpKG1zadwa2R3pg5NBpjYgIhlbC1hL3KVVQirbAcggD0qy60B4AJsUEYExOIHck5eHHjKWz812CLfx18uPMi1FoRw7v5I67WsmdnRynefaAv7lt9ED8lZmB8bBDG9goyPK/fcmFglI9VNpWMDZEbprl/PZmFcpWul1akn+k9tGQOEnT2d8e5bAXKVBo4O0rapCGhJZn8f+Tq1atNPkwhk8kQFxeHHTt21Dm+Y8cODB48uN75np6eOH36NJKSkgyPWbNmoXv37khKSsLAgQNN/XSI2pS+zia1oBw3ylQmv/7t389hz4U8rDuYat7ArExf73A09QZmfXUcI9/djc/3X0Wpkh3P7dGJa0UAdKMMns41je8EQcCbk2Lh4eSApPQifHko1aJxpOaX4afEDADA06O71nv+lk7eeHx4NADglZ/P1Pme1dfbWHIX8KZIJAKGddVNTf133xUAQOcA93otKIwVU2srh4RoX5sfRW1xupmfn4+CgoLmT2zGM888g//+97/4/PPPkZKSgqeffhppaWmYNWsWAN200rRp03TBSiSIjY2t8wgICICzszNiY2Ph5saur9S+ebnKEFX9l1VS9aZ0xrqSV4oreWUAgK2nsyCKornDs4qichVOZxQDAP4xJBJero5IKyzHov8lI+E/f+LfvyXj+o1yK0dJ5nT8WiGAmimp2oLkznhxgq61yNJt55FRVGGxOFbsvAiNVsTI7v7o36nhpdxPj+6GrgHuyC9VYuHmswAAlVqLv67qPgdL7yfVFP1qJv1Kqe4m9Le5We19qmy93gYwMbkpKirC7Nmz4efnh8DAQAQEBMDPzw9z5sxBUVFRiwKYMmUKli1bhkWLFqFfv37Yu3cvtmzZYth9PCsrq9meN0S2RD96k2RiM78/U3IN/04tKDf8QLN1By8XQBSBrgHuWDixFw69NApvTY5FtJ8bFEo1Ptt3FSPe2Y3Z35xAIgux7cLN9TY3mzqgE26N9Ea5SoNXfz5tkUT+cl4pNulHbcY0XsPp7CjFu/f3hVQiYPPJTGw9nYWk9CJUVGng6yZrUY2LuQzrVjex6h7k2ciZzaud3Nh6vQ1gQnJTWFiIgQMH4osvvsDf/vY3vPfee3j33Xdx7733Yt26dUhISMCNGy37wfPkk08iNTUVSqUSx48fx/Dhww3PrVu3Drt37270ta+//jqSkpJa9L5E1qBPbk6aOHKzIyUHAAwdQ7eesX67enPYX127MLR6iN1FJsXDgyLwxzMj8PmMeAzu7AuNVsRvp7Jwz6qD+CUpw5rhUitVVmlwJkPXkqOx5EYiEbD43j6QSSXYdT7PsF+bOX3450VoRWB0zwD0CfNq8ty+4V74V/Umla9uOoP/ndLFM6izLyRWrA0L8HCuM53UkmXgev06eSHUywVDuvi2qG6nvTE6uVm0aBFkMhkuX76MTz75BPPnz8fTTz+NTz/9FJcuXYKjoyMWLVpkyViJ7IIhuaneIdwYN8pUOJaqGwafe3sXALqpKXugL8wcetPwvkQi4PYegfjm8UHYMneYoZfIHiPa4lP7dTazGCqNFn7uMnRqoo9KlwB3PFX9tf7Gr8kobEGNWmMu5SrwS3XCNH+0cStvnxrVBT2CPFBQpsL6Q9cAAEOssAT8ZsNrjbJ0a0Vy4+7kgP0vjsSXj9pH7arRyc2mTZvw7rvvNriKKSgoCEuXLsXPP/9s1uCI7FHPYE/IHHQ7hF8rMK6WZPeFXGhF3V9mjyREwlEq4GJuKS7l2vbUVHphOa4VlMNBImBgdOOFmTEhnpiWEAkAOJdl259zR3e8Vn+b5vqjPTGiM7oHeqCwTIV3t583WwzL/7wEUQTGxgQiNtS4ZdxODrrpKYdaIzVt3byvIfopJLmLI0LkrVtBKQiCVUeizMno5CYrKwu9evVq9PnY2NhGG+8RUQ2ZgwS9TNwh/I9kXb3NmJhAyF0cDaMcW0/b9vecfkqqfycvuDs13ZlCP/x+KbcUVRqtxWMjy2iu3qY2mYMEr90VA0C3g7hW2/ram/PZCsO0krGjNnqxoXLMHqkbTQr3cWly5KmtDIr2wSt39MD7D/RtUTNde2V0cuPn54fU1NRGn7969Sp8fa2fxRLZAkNRsRHJjUqtNUzFjO6pGzmdEBsMANhi43U3+uTGmBUnoV4ucHdygEqjNawaI9siiiKOVy8DNya5AYCB0T5wk0l125Zkt377nOV/XoAo6nrqxISYXoA75/YuePXOnlg2pV+7SCYEQcA/h3fGqJ4NbxHRURmd3IwfPx4LFiyASlV/3lOpVOK1117D+PHjzRockb3SJzeJRiQ3R64WoFSphr+HE3pXD6Hrm9ylZJUgNd82f9FrtaJh48Gb620aIpEIho6158zwS47aXlphOfJLlZBJJUZPBzlKJYYpS319VkulZJVgy+lsCILpoza143lsWHSdhn/U/hid3Lzxxhs4f/48unbtiqVLl2Lz5s3YvHkzlixZgq5duyIlJQWvv/66BUMlsh/65CaleofwpvyRrFslNbpngGE+3NtNhsHVzcNsddVUclYJbujb1xu5iWjPYF1yk8K6G5ukn5KKDfU0qUmcfmTvwKXW9VZb9scFAMAdbbS1A1mP0clNWFgYDh06hJiYGLz88suYPHkyJk+ejAULFiAmJgYHDhzgnk1ERtLvEK7SaJGc2fgohCiK+KO6v83om4adx8fqWsFvPWObq6b0U1KDon2M7qraI6hmgz+yPabU29SmH9n762phs38MNOZ8tgLbzuboRm1G1e9GTPbFpCZ+UVFR2Lp1K/Lz83H48GEcPnwYeXl5+P3339GlSxdLxUhkd+rsEN7E1NS5bAUyiirg7CipV5cyNiYIEgE4db3YJjv47r9ofL2Nnn7khtNStqmlyU23QHf4uTuhokqDRBObX+r9Vl1EPKpHILpasfEetY0Wbb/g7e2NAQMGYMCAAfDx4bwjUUv0C9f9gG8qudFPSQ3t4l9vGN/fwwm3Ruq+/363sampyioN/qru26PfH8cY+g6sOSVKs/Y9IctTVFbhfPXO1bc0stVBYwRBMCy7PtjCupvt1d9LE2KDmjmT7EHbb2VKRABqdkNuMrk5p18C3vBeL3f0rl41ZWMN/Y5fuwGVWotATyd09jd+Pxx3JwfD8ttznJqyKUnpRRBF3RLqgBbsaK8f4dvfguQmvVC3XYlUIuD2Hra/bxI1j8kNkZX0q275fq2gvMFRiNySSpysTnxGNvIDWV93cyKtCNnFlRaJ0xL21ZqSMnU5raGo2E721uooDFNSJo7a6OmTm5PXi1FSWWXSa/WjNvER3vB2k7Xo/cm2MLkhshK5qyOiq/dwOdnA6M2f1aM2/cK9EODR8F+6gZ7OhvqF300oLE7OLMHbv59DpgV3XG6KfkmvKVNSeiwqtk2G5CayZaUMoV4uiPJzg0Yr4siVQpNeuyNZN207thenpDoKJjdEVtRUM78/U2qWgDdlgmHVlHF1N5lFFXh4zRGs3n0Zd324v9W9Q0x1o0yFM5nFAFq2Nw+Lim2PRisaCoFbOnID1Gx3YMrX7I0yFY6m6hKrsTFsdNdRMLkhsqK+jSQ3FSqNYepmdDM/kPVTU3+lFiJPoWzy3MoqDf711XEUlqkglQgoLFPhkepEx9hNPFvr4OUCiKJuBUxLai96Vm/DcCGnFGpuw2ATLuQoUKpUw00mbVV/GX0ybEpys/NcLjRaET2CPBDeDrZLoLbB5IbIigw7hF+vu0P4/kv5UKq1CPN2Qfdmlq2Gebuib5gcoghsO9v46I0oilj4y1mcvF4ML1dHbJs/HPfHhUErAm//fg6zvjoOhYm1DC2x39CV2L+ZMxsW7u0KV5kUKrUWV220O7Ot02hFbErMQG6JcXVe+imp/p28IW3FxowJnX0hCMDF3FLkGPneO6rrbcZw1KZDYXJDZEX6HcKLyquQWmuH8JopqUCjCm4nVK+aampJ+Ld/pWPDsXRIBODDB/ujS4A7lt7XB/+5pzdkUgm2nc3BpI8O4EKOZQt19X91D+3asr3oam/DwKJi6/glKQPzNyRhyqeHUapUN3v+Cf1O4Cb2t7mZl6vMsAXJwcvNj95UVmmw96JuX7axMay36UiY3BBZUd0dwnW/ALTaxrsSN0Zfd3PoSkGDK69OpN3Aws1nAADPjeuOYV11oyaCIGDqwE74flYCguXOuJJfhskrD+DXk5mt+8QakVZQjrTCcjhIBAyIavlGu/qpKS4Htw79lOnV/DK88tPpZqc0j6e1rHlfQwZXT03tv9j8VgwHL+ejXKVBsNwZsaGmb5JJtovJDZGVGYqKqwsuT14vQn6pEh5ODhgQZdzKkghfN8QEe0KjFQ0rQ/TyFEo8+dUJVGlETIgNwr9GdG4whv89NRSDO/uiXKXBU98m4s3/JaPKzDUt+impWzp5w93JocXX6akfuWFy0+ZEUcSRKzWJxeaTmfjuaHqj5+cplLhWUA5BAPpX93ZqjaFdaupumkuqdiSbNgJK9oPJDZGV3bxi6s/qUZvh3f0hczD+W7ShVVNVGi1mf3MC2SWV6BLgjnfu79voD3lfdyesf3QA/nWbLvlZs/8qHvrsCIrKzdcJWD8lZcqWCw0xjNxwWqrNXb9RgcziSjhIBMyr3qPp9c1nG000T1SP2nQP9ICns2Or3z8+0hsyBwmySypxpYmaK61WxI5kfRNM1tt0NExuiKysf/U2DMlZJais0uCP6nqbMUZOSenp624OXMpHcYWuMHjxlnP462oh3J0c8Mkjcc2OljhIJXhxfA98/LDu3L9SC/HCj6fMspJKoxVx4HLr6m30ulWP3GQVV5o1+aLmHa4etekTJse8UV0xsrs/lGotZn99osH6m+NmqrfRc3aUIr76Wk2tmkpMrxkBHRTduq83sj1MboisLNzHBT5uMlRpRGxPzjG0ib+tu2mriboEuKNboDuqNCL+TMnBL0kZ+PzAVQDAew/0NWmbg/GxQfj28UFwlArYnpyD7481Pu1grOTMEhSVV8HdyQF9q7szt5SnsyPCvF0AAClZHL1pS0eu6hroDYz2hUQi4L0H+iHIU1ev9erP9etvWtuZuCGGrRguNp7c6KekbusRYNIIKNkH/h8nsrLaO4Qv++MCAF2beC9X09vEj4/Vjd6s2X8VL248BQCYM7ILxrWgM2vvMDmeHdsdAPDGr8m4VtC6Zdf6eptB0b5wkLb+R0/N1BTrbtqSfuRmYHU9mI+bDB9O7Q+pRMCmpMw6ibBSrcHp67qGjeYoJtbT190culLQaK8jfe0Zp6Q6JiY3RO2AfofwK3m6BKKlP5Dv6K1LYs5mlqCySosR3fzx9JhuLY7r8WHRGBjlg3KVBvM3JLWqad7+S7oluUO7mGeKgEXFbS+jqALXb1RAKhEQX2sbhVsjffBcdSL8f7+cNSScZzJKoNJo4esmQ4Sv+RroxYbK4ensAEWlGmcy6///v5xXist5ZXCUmj4CSvaByQ1RO9DvplUko0yst9HrHuiBqOr9qsJ9XLD87/1a1TRNKhHw3gN94eHkgMS0IqzafblF16ms0hha4A/tap5fNj1YVNzm9KukYkM869VvPTE8GrfVqr8pU6rr9Lcx52olqURAQufGt2LQT0kNivY1SxEz2R4mN0TtQL9aNSid/d0MCYqpBEHAc2O7Y0CUDz6bFt+iqa2bhXm7YtHkXgCA5X9ebHAfrOYcTS2ESq1FkKczOvu37HO7mX5a6ny2Ahpt22wd0dHpN6wc2ECBrkQi4L37+yLI0xmX88rw2qYzOHZNd745p6T0hjZRd8OuxMTkhqgdqL1DeHN7STXnzj7B+P6JBMPu2eYwuV8o7uoTDI1WxNMbklCuar4rbW37ay0BN9df8J18XOHiKIWS2zC0mSNX69bb3MzX3QkrHtTV3/yUmGFoaxBvgeRmcHVyc/zaDVSoNIbjeQqlYfm5sU0wyf4wuSFqJ2YMiUS0vxumDuhk7VDqEQQB/57cG0GezriaX4a3fksx6fX6qYNhXVvX36Y2aa1tGFhUbHk5JZVIrW7GV7ve5mYDonzwTHWdl1orwlEqILZ6ywRzivZzQ7DcGSqN1jBCBAA7z+VAFIHeoXKEeLmY/X3JNjC5IWonpiVEYueztyHC1zzTNuYmd3XEew/0BQB8cyTNsP9VcwrLVDhbXfQ52EzFxHo9g6uTGy4Hb1KVRovz2Qr8kpSBlbsuIb2wvPkX3US/Siom2BNyl6brWP41ojOGd9PVVsWGyuHsKDU96GYIglCzJLxW3Q2npAgAWt7/nIg6nCFd/DBzaJRhqfnv84fDz92pydfsOpcLUdQVOwd4OJs1Hv3UW3tdMaXViki6XoQ+oXKzLH9vjiiKyFUokZJVgvPZCpzLViAlqwSX80pRpampSzp4OR9fPzbIpGsb+tsYsSeYRCJg+ZR+WLHzIu7qE2zaJ2GCIV188ePx6zh4SZd4lavUhn2vmNx0bExuiMgkz4/rjv0X83E+R4GXNp7CZ9Pi69TRVGm0OH7tBnadz8Wuc7m4kFMKoPVbLjSkJdsw6BOOXiGecHIw/4hCbd/8lYZXN53B48OisODOGIu+1/FrhXjqm0RkFlc2+Ly7kwO6BbojMb0IBy4VIL2wHOE+xi/P1q+UGhht3H5n3m4yLJzYy+jrt8SQ6k00z2QW40aZCkeuFkKp1iLM2wU9qqcsqWNickNEJnF2lGLZ3/th0kcH8EdKLr47mo4xMYHYfT4Pu87nYu+FPCgqawqOpRIBt0Z6Y8bgSLPHoq+5ySiqQHF5FeSuzS/7XbrtPD7ecxmxoZ5Y/VCcSb/gTaWfIvnur3Q8PaYbXGWW+ZFbVK7CnG8SkVVcCYkARPm5oUewJ3oGeaB7kCd6BHkgzNsFgiDgof8exoFLBdh44jrmjzauB1KeQonL1T2YBjRRb9PWAjyd0S3QHRdySnHoSoGhgHlsTBA3yuzgmNwQkcl6Bnvi+XHd8e8tKXht0xm88vNp1O667+Mmw23d/DGyRwCGd/U3KuloCbmLI0K9XJBRVIFz2SUNLlGurbBMhS8OpgLQNZib+NF+fPhgfwwzU++d2qo0WhxL1U3lKJRq/O9kFh64Ndzs7yOKIl7ceApZxZWI8nPDL3OGNNnb5YH4cBy4VIAfjl3H3Nu7QmJEH6S/qqekegR5wNut9e0FzGlwZz9cyCnF3gt52HmO9Takw4JiImqRmUOjMLizL9RaEaIIxIZ6Yu7tXfDTk4NxdMFovD+lHyb2DbFYYqNnKCo2Ympq3cFUVFRp0CPIA71D5Sgqr8L0z//Cyl2XzLI5aG1nMopRVmuJ8jd/pZn1+rWvu+1sDhylAlb8vX+zTevG9QqCh7MDMooqDEXCzWluCbg16fvd/HQiAzfKq+Dl6ohbI82/9JxsC0duiKhFJBIBn06Lx8FL+egb7oVAT/MWCxurR5An/kjJbbaouFSpxrrqjUTnjeqKkT0CsPCXs9hwLB3vbDuPk+lFum7MZupoqy/AjY/wxsnrRUhKL0JyZgliQszXf+hijgJv/i8ZgK4WqndY80uunR2lmNg3BN8cScMPx68b+sU0panmfdY2MNoHUokAVfXWILd3D2iT4m1q3/gVQEQt5u7kgLG9gqyW2AA1RcUpzYzcfHPkGkoq1Yj2d8O4XkFwdpTi7fv6YPG9vSGTSrA9OQeTVh7AxRzzLCvXj4pM6B2MsdUbl35rxtGbyioNnvo2EZVVWgzr6ofHhkYb/doH4nXTY1tOZ6GksqrJcwvLVDhffU8GtMORGw9nR8PGswCnpEiHyQ0R2bQe1dNSF5rYhqGySoPP9ulGbf41onOdOpMHB3TC97MSECx3xpW8MkxaeQBbTme1Kia1Rouj1SM3g6J98FB1Y8ZNiRkmd3duzJKt53AuWwFfNxnee6CvUbUzen3D5Oga4A6lWov/nWz6c9XX23QJcG922b+16KemZA4SQ38d6tiY3BCRTYv0dYOzowQVVRpcK2h4G4Yfj19HnkKJELkzJvULrfd8v3Av/PrUUCRE+6JcpcGTX5/A4i0pLd4F/UxmCcpUGshdHNEzyBODon0R6etqKCxurZ3ncrCuujD63fv7mtw/SBAE3B8fBgD44Xh6k+e253obvbv6hsDJQYJ7+4fCzYnVFsTkhohsnFQioHtg40XFao0Wn+zV7Wb+z+HRkDk0/GPPz90JX84cgCeG66Z3Ptl7BZ/svdKimPRTUgOifCCRCJBIBPy9evTm61ZOTeWWVOL5H04BAGYMjsTIHgEtus49/cMglQhITCvCpdzGp+L09TaD2mG9jV63QA8k/d9Y/Pue3tYOhdoJJjdEZPOa6lT8v1NZSC+sgK+bDFNubXrfLgepBC/f0ROv3aVruLcpMaNF8Rga3tUa7bgvLgyOUgEn04twNrO4RdfVakU8+8NJFJSp0DPYEy9N6NGi6wCAv4cTRnbXJUY/HLve4DnF5VVIqd63y9jmfdbiIpNCasLUHNk3JjdEZPP0dTcpN+0xpdWKWL1bN2rz6NAouMiM60isT0Qu5pbiUm6pSbGoNVocTdXtSl17tMPP3clQWPzdX01PBTVmzf6r2HcxH86OEnz4YL9W79mkn5raeCIDVQ1MwR1NLYQo6japNPfWGUSWxOSGiGxezTYMdUdu/jyXi/M5Crg7OeDhQRFGX0/u4ojB1a39t53NNimWs5klKFWq4ensYIhLrzWFxaevF2PptnMAgP+7qxe6BLR+e4HbewTAz12G/FIl9pzPq/e8od6mnY/aEN2MyQ0R2bye1dNS129UGJY2i6KIlbsuAQAeSYhodifrm42P1Y2y/H7GtOSmpt7Gt940SUsLi8uUasz9LhFVGhHjewXhwQHm6XTsKJVgcnWBdUOFxaZslknUnjC5ISKbJ3d1RIhcN21yvrqo+NCVAiSlF8HJQYJHh0SZfM0xMYGQCMDpjGJcv1Fu9OuO1FoCfrOWFBar1Fo8+fUJXM0vQ7DcGUv+1tus+ybdX93z5s+UXBSUKg3HFZVVOJOhqw3iyA3ZGiY3RGQXeuinpqqLivW1NlNuDYe/h+n9WfzcnXBr9SaR287mGPWauv1tGh7tMKWwWKMV8fT3SdhzIQ/OjhJ8NPUWeLmad2+n7kEe6Bsmh1or4udaBdTHrt2AVgQ6+bgiWO5i1vcksjQmN0RkF3pU7xCenKXAyfQi7LuYD6lEwOPDjO/cezP91NQ2I6emkrNKoFCq4dFAvY1e7cLipjoWi6KIVzedxm+nsuAoFfDJI/GIi7DMnkn3VY/e/Hj8umGPLcOWC+24vw1RY5jcEJFdqF1UvGq3rtZmUr8QhPu4tvia46qTkKPXCpGnUDZzdk29zcAonyaXJdcUFmc2Wli85Pdz+PavdEgEYNmU/hhhwc67d1c3wTuXrcCZDN3IV00xMettyPYwuSEiu6DfHfxsRolhGulfIzq36pohXi7oGyaHKAI7kpufmjpsZMM7fWFxaSOFxat2X8Ine3QNBP9zT2/c2Se4BdEbT+7iaEjkvj+WjnKVGqevV9fbcOSGbBCTGyKyC5G+bpA5SAy7Q4/rFYiuga1fLj1Ov2qqmSXhGq1oqLdpbnVRU4XFXx2+hqW/nwcALLijp+E8S9P3vPklKQOHLhdArRUR6uXSqpEvImthckNEdsFBKjFswwAAT97WxSzXHV89onHwUj6KKxrfQTs5s7rexskBMSEN19vU1lBh8S9JGXjtlzMAgDkju+Dx4S2vFzLV4M5+CPVyQUmlGku26vrpcNSGbBWTGyKyG/qpqaFd/NA33Mss14z2d0e3QHeotSL+TGl8aqr2flLGbANwc2HxznM5ePb7kxBFYFpCBJ4d280s8RtLKhHwt1t0PW8uVndl5hJwslVMbojIbvxzeDQm9QvBokm9zHpd/ehNUw399MmNKRtM6guLfzqRgX99dQJqrYjJ/ULw+sReZu1lY6z74uo2B2TzPrJVTG6IyG50CfDA8r/3R7S/u1mvq6+72XMhr8HVTRqtiL9Sq+ttTBjt0BcWl6s0UKq1GN0zAO/c3xcSK20A2cnX1dB8MNDTCRG+rLch28TkhoioGTHBngj3cYFSrW1wD6aUrBIoKqvrbRrpb9MQiUTAtIRIALr6lo+m3gJHqXV/LM8YrOvmPL5XkFVGj4jMwcHaARARtXeCIGB8ryB8tu8qfj+bjQm96y7N1k9J3RrlAwcTk5MZgyPRJ0yOPmFekDlY/+/N8bFB2PnsCIR6sysx2S7rfycREdmA8bG6hGZnSi6Uak2d52rqbUwvwJVIBMRH+rSLxEYv2t8dTg5Sa4dB1GLt57uJiKgd6x/uhQAPJyiUahy8XGA4rtGKtTbLZAEuUXvA5IaIyAgSiWDo4lt7ryl9vY27ifU2RGQ5TG6IiIyk30hze3IONFrdBpOGeptIb5PrbYjIMvidSERkpAFRPvBydURhmQp/VU9FGbufFBG1HSY3RERGcpRKMLpnIABg29lsXX+bq6Y37yMiy2JyQ0RkgtrdilOySlBSXW/Ty4j9pIiobTC5ISIywdCufnCVSZFdUolP914BAMSz3oaoXeF3IxGRCZwdpRjZIwAAsPlkJgBOSRG1N0xuiIhMpJ+a0mNyQ9S+MLkhIjLRyB4Bho7CbjIpYllvQ9SuMLkhIjKRu5MDhnf1AwDER5q+nxQRWRa/I4mIWuCJEZ3RyccVMwZHWjsUIroJdwUnImqBWyN9sPeFkdYOg4gawJEbIiIisitMboiIiMiuMLkhIiIiu9IukptVq1YhKioKzs7OiIuLw759+xo9d//+/RgyZAh8fX3h4uKCHj164IMPPmjDaImIiKg9s3pB8YYNGzB//nysWrUKQ4YMwSeffIIJEyYgOTkZnTp1qne+m5sb5syZgz59+sDNzQ379+/HE088ATc3N/zzn/+0wmdARERE7YkgiqJozQAGDhyIW265BatXrzYc69mzJyZPnozFixcbdY17770Xbm5u+PLLL5s9t6SkBHK5HMXFxfD0ZOMtIiIiW2DK72+rTkupVCocP34cY8eOrXN87NixOHjwoFHXSExMxMGDBzFixIgGn1cqlSgpKanzICIiIvtl1eQmPz8fGo0GgYGBdY4HBgYiOzu7ydeGhYXByckJ8fHxmD17Nh577LEGz1u8eDHkcrnhER4ebrb4iYiIqP1pFwXFgiDU+VgUxXrHbrZv3z4cO3YMH3/8MZYtW4Zvv/22wfNefvllFBcXGx7p6elmi5uIiIjaH6sWFPv5+UEqldYbpcnNza03mnOzqKgoAEDv3r2Rk5OD119/HQ8++GC985ycnODk5GS+oImIiKhds+rIjUwmQ1xcHHbs2FHn+I4dOzB48GCjryOKIpRKpbnDIyIiIhtk9aXgzzzzDB555BHEx8cjISEBn376KdLS0jBr1iwAummljIwMrF+/HgCwcuVKdOrUCT169ACg63vz7rvv4qmnnrLa50BERETth9WTmylTpqCgoACLFi1CVlYWYmNjsWXLFkRERAAAsrKykJaWZjhfq9Xi5ZdfxtWrV+Hg4IDOnTtjyZIleOKJJ6z1KRAREVE7YvU+N22NfW6IiIhsjym/v60+ctPW9Lkc+90QERHZDv3vbWPGZDpccqNQKACA/W6IiIhskEKhgFwub/KcDjctpdVqkZmZCQ8Pj2Z76ZiqpKQE4eHhSE9P55SXBfE+tw3e57bDe902eJ/bhqXusyiKUCgUCAkJgUTS9GLvDjdyI5FIEBYWZtH38PT05DdOG+B9bhu8z22H97pt8D63DUvc5+ZGbPTaRYdiIiIiInNhckNERER2hcmNGTk5OWHhwoXc7sHCeJ/bBu9z2+G9bhu8z22jPdznDldQTERERPaNIzdERERkV5jcEBERkV1hckNERER2hckNERER2RUmN2ayatUqREVFwdnZGXFxcdi3b5+1Q7J5e/fuxcSJExESEgJBELBp06Y6z4uiiNdffx0hISFwcXHBbbfdhrNnz1onWBu2ePFi3HrrrfDw8EBAQAAmT56M8+fP1zmH97r1Vq9ejT59+hgamyUkJGDr1q2G53mPLWPx4sUQBAHz5883HOO9br3XX38dgiDUeQQFBRmet/Y9ZnJjBhs2bMD8+fOxYMECJCYmYtiwYZgwYQLS0tKsHZpNKysrQ9++ffHRRx81+PzSpUvx/vvv46OPPsLRo0cRFBSEMWPGGPYPI+Ps2bMHs2fPxuHDh7Fjxw6o1WqMHTsWZWVlhnN4r1svLCwMS5YswbFjx3Ds2DHcfvvtmDRpkuEHPu+x+R09ehSffvop+vTpU+c477V59OrVC1lZWYbH6dOnDc9Z/R6L1GoDBgwQZ82aVedYjx49xJdeeslKEdkfAOLPP/9s+Fir1YpBQUHikiVLDMcqKytFuVwufvzxx1aI0H7k5uaKAMQ9e/aIosh7bUne3t7if//7X95jC1AoFGLXrl3FHTt2iCNGjBDnzZsniiK/ns1l4cKFYt++fRt8rj3cY47ctJJKpcLx48cxduzYOsfHjh2LgwcPWikq+3f16lVkZ2fXue9OTk4YMWIE73srFRcXAwB8fHwA8F5bgkajwXfffYeysjIkJCTwHlvA7Nmzceedd2L06NF1jvNem8/FixcREhKCqKgo/P3vf8eVK1cAtI973OE2zjS3/Px8aDQaBAYG1jkeGBiI7OxsK0Vl//T3tqH7fu3aNWuEZBdEUcQzzzyDoUOHIjY2FgDvtTmdPn0aCQkJqKyshLu7O37++WfExMQYfuDzHpvHd999hxMnTuDo0aP1nuPXs3kMHDgQ69evR7du3ZCTk4O33noLgwcPxtmzZ9vFPWZyYyaCINT5WBTFesfI/HjfzWvOnDk4deoU9u/fX+853uvW6969O5KSklBUVISNGzdi+vTp2LNnj+F53uPWS09Px7x587B9+3Y4Ozs3eh7vdetMmDDB8O/evXsjISEBnTt3xhdffIFBgwYBsO495rRUK/n5+UEqldYbpcnNza2XtZL56Kvyed/N56mnnsLmzZuxa9cuhIWFGY7zXpuPTCZDly5dEB8fj8WLF6Nv375Yvnw577EZHT9+HLm5uYiLi4ODgwMcHBywZ88erFixAg4ODob7yXttXm5ubujduzcuXrzYLr6emdy0kkwmQ1xcHHbs2FHn+I4dOzB48GArRWX/oqKiEBQUVOe+q1Qq7Nmzh/fdRKIoYs6cOfjpp5+wc+dOREVF1Xme99pyRFGEUqnkPTajUaNG4fTp00hKSjI84uPj8dBDDyEpKQnR0dG81xagVCqRkpKC4ODg9vH13CZly3buu+++Ex0dHcU1a9aIycnJ4vz580U3NzcxNTXV2qHZNIVCISYmJoqJiYkiAPH9998XExMTxWvXromiKIpLliwR5XK5+NNPP4mnT58WH3zwQTE4OFgsKSmxcuS25V//+pcol8vF3bt3i1lZWYZHeXm54Rze69Z7+eWXxb1794pXr14VT506Jb7yyiuiRCIRt2/fLooi77El1V4tJYq81+bw7LPPirt37xavXLkiHj58WLzrrrtEDw8Pw+89a99jJjdmsnLlSjEiIkKUyWTiLbfcYlhGSy23a9cuEUC9x/Tp00VR1C03XLhwoRgUFCQ6OTmJw4cPF0+fPm3doG1QQ/cYgLh27VrDObzXrffoo48afkb4+/uLo0aNMiQ2osh7bEk3Jze81603ZcoUMTg4WHR0dBRDQkLEe++9Vzx79qzheWvfY0EURbFtxoiIiIiILI81N0RERGRXmNwQERGRXWFyQ0RERHaFyQ0RERHZFSY3REREZFeY3BAREZFdYXJDREREdoXJDREREdkVJjdEZDVVVVVYt24dhg4dCn9/f7i4uKBPnz54++23oVKprB0eEdkodigmIqtJSkrCs88+iyeffBL9+/dHZWUlTp8+jddffx1BQUHYvn07HB0drR0mEdkYjtwQkdXExsbizz//xN/+9jdER0cjJiYGU6ZMwd69e3H27FksW7YMACAIQoOP+fPnG65148YNTJs2Dd7e3nB1dcWECRNw8eJFw/OPPvoo+vTpA6VSCUA3ahQXF4eHHnrIcM6LL76Ibt26wdXVFdHR0XjttddQVVXVJveCiMyHyQ0RWY2Dg0ODx/39/XHvvffi66+/Nhxbu3YtsrKyDI+EhIQ6r5kxYwaOHTuGzZs349ChQxBFEXfccYchOVmxYgXKysrw0ksvAQBee+015OfnY9WqVYZreHh4YN26dUhOTsby5cvx2Wef4YMPPjD3p01EFtbwTxYiojbUq1cvXLt2rc6xqqoqSKVSw8deXl4ICgoyfCyTyQz/vnjxIjZv3owDBw5g8ODBAICvv/4a4eHh2LRpE+6//364u7vjq6++wogRI+Dh4YH33nsPf/75J+RyueE6r776quHfkZGRePbZZ7Fhwwa88MILZv+cichymNwQkdVt2bKl3vTP0qVL64zcNCUlJQUODg4YOHCg4Zivry+6d++OlJQUw7GEhAQ899xzePPNN/Hiiy9i+PDhda7z448/YtmyZbh06RJKS0uhVqvh6enZis+MiKyByQ0RWV1ERES9Y5cvX0bXrl2Nen1j6yJEUYQgCIaPtVotDhw4AKlUWqceBwAOHz6Mv//973jjjTcwbtw4yOVyfPfdd3jvvfdM+EyIqD1gzQ0RWU1hYSEUCkW948eOHcOuXbswdepUo64TExMDtVqNI0eOGI4VFBTgwoUL6Nmzp+HYO++8g5SUFOzZswfbtm3D2rVrDc8dOHAAERERWLBgAeLj49G1a9d6U2VEZBuY3BCR1aSlpaFfv35Ys2YNLl26hCtXruDLL7/EpEmTMGzYsDqroZrStWtXTJo0CY8//jj279+PkydP4uGHH0ZoaCgmTZoEQLfs/P/+7/+wZs0aDBkyBMuXL8e8efNw5coVAECXLl2QlpaG7777DpcvX8aKFSvw888/W+pTJyILYnJDRFYTGxuLhQsXYt26dRg0aBB69eqFpUuXYs6cOdi+fXudouHmrF27FnFxcbjrrruQkJAAURSxZcsWODo6orKyEg899BBmzJiBiRMnAgBmzpyJ0aNH45FHHoFGo8GkSZPw9NNPY86cOejXrx8OHjyI1157zVKfOhFZEJv4ERERkV3hyA0RERHZFSY3REREZFeY3BAREZFdYXJDREREdoXJDREREdkVJjdERERkV5jcEBERkV1hckNERER2hckNERER2RUmN0RERGRXmNwQERGRXWFyQ0RERHbl/wF8QQ9JHyMDGgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history)\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Ошибка на тестовой выборке')\n",
    "plt.title('Динамика ошибки модели RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[269  26]\n",
      " [ 79 382]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch.cuda()).argmax(dim=1).cpu().detach()\n",
    "print(confusion_matrix(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8670612890179786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch.cuda()).argmax(dim=1).cpu().detach()\n",
    "print(roc_auc_score(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "review = 'Отдых ужасный'\n",
    "x = train_dataset.vectorize(review).unsqueeze(0)\n",
    "predictions = model(x).argmax(dim=1).cpu().detach()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "review = 'В сочи было очень хорошо. Приветливый персонал'\n",
    "x = train_dataset.vectorize(review).unsqueeze(0)\n",
    "predictions = model(x).argmax(dim=1).cpu().detach()\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "review = 'Было очень грязно'\n",
    "x = train_dataset.vectorize(review).unsqueeze(0)\n",
    "predictions = model(x).argmax(dim=1).cpu().detach()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "review = 'отзыв о кафе грейс: К сожалению, наш поход в данное заведение нам совершенно не понравился. Уже с самого начала все незаладилось, после того, как нас 20 минут не могли посадить и еще столько же принять заказ. Прождав 30 минут, мы сами взяли кофе со стойки и шарлотку, которая оказалась сухой. Единственное, нужно отдать должное менеджер пытался координировать персонал, но это особо не помогало. Организации абсолютно не было, что испортило наш визит'\n",
    "x = train_dataset.vectorize(review).unsqueeze(0)\n",
    "predictions = model(x).argmax(dim=1).cpu().detach()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(config):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    \n",
    "    model = LSTMModel(\n",
    "        embeding_m=model_w2v,\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        output_dim=2,\n",
    "        n_layers=2,\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "    \n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    criterion = criterion.to('cuda')\n",
    "\n",
    "    for epoch in range(config['epoch_number']):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            predictions = model(X_batch.cuda())\n",
    "            loss = criterion(predictions, y_batch.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loss, val_acc = 0, 0\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                predictions = model(X_batch.cuda())\n",
    "                loss = criterion(predictions, y_batch.cuda()).item()\n",
    "                acc = accuracy_score(y_batch, predictions.argmax(dim=1).cpu().detach()).item()\n",
    "                val_loss += loss\n",
    "                val_acc += acc\n",
    "        \n",
    "        \n",
    "        \n",
    "        session.report({\"val_loss\": val_loss / len(test_loader)})\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            print(f'{config.items()}. {val_loss / len(test_loader)}')\n",
    "            torch.save(model.state_dict(), \"E:/Programming/DL_CurseWork/models/model.pth\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'batch_size': tune.grid_search([16, 32]),\n",
    "    'hidden_dim': tune.grid_search([256, 512]),\n",
    "    'dropout': tune.grid_search([0.2, 0.3, 0.4, 0.5, 0.6, 0.7]),\n",
    "    'epoch_number': tune.grid_search([25, 35, 45, 60])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-30 21:21:03</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:15.21        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.9/15.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: 0.615955193565848 | Iter 4.000: 0.67178372759372 | Iter 1.000: 0.6687338013822833<br>Logical resource usage: 6.0/6 CPUs, 1.0/1 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  epoch_number</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_lstm_079c0_00001</td><td>RUNNING   </td><td>127.0.0.1:18488</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         101.033</td><td style=\"text-align: right;\">  0.689491</td></tr>\n",
       "<tr><td>train_lstm_079c0_00002</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.3</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00003</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.3</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00004</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00005</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00006</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00007</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00008</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.6</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00009</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.6</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00010</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.7</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00011</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.7</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00012</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">            35</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00013</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">            35</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00014</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.3</td><td style=\"text-align: right;\">            35</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00015</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.3</td><td style=\"text-align: right;\">            35</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00016</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">            35</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00017</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">            35</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_lstm_079c0_00000</td><td>TERMINATED</td><td>127.0.0.1:18488</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      0.2</td><td style=\"text-align: right;\">            25</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         181.174</td><td style=\"text-align: right;\">  0.421298</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:16:10,864\tWARNING worker.py:1986 -- Warning: The actor ImplicitFunc is very large (27 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2023-04-30 21:16:10,962\tWARNING util.py:244 -- The `start_trial` operation took 1.634 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>date               </th><th>done  </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_lstm_079c0_00000</td><td>2023-04-30_21-19-15</td><td>False </td><td>DESKTOP-F7DMKF0</td><td style=\"text-align: right;\">                        24</td><td>127.0.0.1</td><td style=\"text-align: right;\">18488</td><td style=\"text-align: right;\">             174.113</td><td style=\"text-align: right;\">           7.16799</td><td style=\"text-align: right;\">       174.113</td><td style=\"text-align: right;\"> 1682878755</td><td style=\"text-align: right;\">                  24</td><td>079c0_00000</td><td style=\"text-align: right;\">  0.410266</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6682854580382506\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6773765409986178\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.4245818741619587\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.40856688112641376\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.4238090000580996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6688832491636276\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6783007631699244\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.696622408926487\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6850846310456594\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6826977531115214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.670781875650088\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6864930416146914\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.42476089764386415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 25)]). 0.6710209026932716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 25)]). 0.6739402245730162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 25)]). 0.6725913658738136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.671551525592804\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.6720385774970055\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.6803241496284803\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.6826434110601743\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.38013903858760995\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.3695850223302841\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.43822718132287264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.6713687665760517\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.6680118292570114\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.4511464911823471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.6745492468277613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 35)]). 0.6753064095973969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6717548407614231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6766131445765495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 45)]). 0.6719746043284734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 45)]). 0.6728250359495481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.6743100397288799\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.6823292076587677\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.6936916174987952\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.6897871221105257\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.7022280332942804\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.49653980943063897\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.4578261288503806\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.39978731485704583\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.3872982788598165\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.436034931781857\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.47952547993433353\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 60)]). 0.45365842697598663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 60)]). 0.6714886774619421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 60)]). 0.675245085110267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 60)]). 0.6747861181696256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.6719245538115501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 25)]). 0.673639565706253\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 25)]). 0.6954590280850729\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 25)]). 0.673108734190464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6728511191904545\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6800628503163656\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6990766848127047\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.7065256188313166\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.7053140625357628\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6799190106491247\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.7023341295619806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 35)]). 0.6720494826634725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6725088966389497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6744880278905233\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6857210273543993\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6892347782850266\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.686477410296599\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6900799348950386\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6865226303537687\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6932165200511614\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.700469620525837\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6911859959363937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.679651539772749\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6754344763855139\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6870071093241373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6759627343465885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6781079235176245\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6660336516797543\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.688566525777181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6723254323005676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6756831755240759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6737943862875303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6726481678585211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 25)]). 0.672376765559117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 25)]). 0.673516129453977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 25)]). 0.677398386100928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 25)]). 0.6748431225617727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6727961786091328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 45)]). 0.6745848879218102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 45)]). 0.6800306091705958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 60)]). 0.6726864986121655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 60)]). 0.6755105207363764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 60)]). 0.6768239426116148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6723650172352791\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6726211781303088\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6725336189071337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6773688544829687\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6723509455720583\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6884095172087351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6771878680835167\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6870994530618191\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6884533849855264\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.7023798314233621\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.3989616804756224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6739305655161539\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6893106885254383\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6923197644452254\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.7014889232814312\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6922036583224932\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6987491759161154\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.690268707772096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 35)]). 0.6721025655666987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6725922475258509\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6741466820240021\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.681528868774573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6746062089999517\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6757660433650017\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6805666834115982\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.691172237197558\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.694062240421772\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6991304953893026\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.7112579445044199\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.7042813127239546\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.698514940838019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6873210749278466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6742036206026872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6750397756695747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.675673745572567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 25)]). 0.6748793621857961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 25)]). 0.6725072202583154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 35)]). 0.6734599980215231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 35)]). 0.6744211663802465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 45)]). 0.6824101482828459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 45)]). 0.6770008951425552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 45)]). 0.6720429708560308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6774404135843118\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6766246072947979\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6804179549217224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 60)]). 0.6814435596267382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.675861082971096\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.6675218790769577\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.679592010875543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 25)]). 0.6727553034822146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 25)]). 0.6784905356665453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6752153088649114\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6737239683667818\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6681781634688377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6758661593000094\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6823729487756888\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6857565927008787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6731578422089418\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6879654613633951\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.4538640493216614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6732804129521052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6784379010399183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6856923885643482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6739849150180817\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6745659932494164\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6890182867646217\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.7008469750483831\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6877633705735207\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6868612170219421\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6838835577170054\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.5620017113784949\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4259570762515068\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.40591326666375\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.37612292915582657\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4386996010628839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6769522403677305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.676278080791235\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6854900854329268\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.7419407808532318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6815691689650217\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6714769005775452\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6946223763128122\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6897452250123024\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.4307302978510658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6747043058276176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 25)]). 0.6738507822155952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.6725417959193388\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.6747726810475191\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.5361956227570772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 35)]). 0.6735333229104677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6749449173609415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 60)]). 0.6732610662778219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.672239520897468\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6777465082705021\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6932218745350838\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6899709279338518\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6969715977708498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 25)]). 0.6733534783124924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6727258463700613\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6837834330896536\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6904120594263077\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.691805778692166\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6938418770829836\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.6909716619799534\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.7060955514510473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6732364222407341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6732990257441998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6760587294896444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.673357542604208\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6787529190381368\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6880748892823855\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6956072635948658\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6969825252890587\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6974857759972414\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.38220714032649994\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.38684353690283996\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.4007924024093275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6724788416177034\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6881024489800135\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6813897341489792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6800473804275194\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6762259950240453\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6793899262944857\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6903576304515203\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6943410014112791\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.44082209762806696\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.3693591958532731\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.38779738964512944\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.40344143903348595\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.4217416140406082\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.4348811683206198\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.4452532584546134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6720808707177639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6771721678475539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 25)]). 0.6851853802800179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 25)]). 0.6728817746043205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 25)]). 0.674434669315815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 25)]). 0.6778592169284821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.6722672370572885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 35)]). 0.672497653712829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 35)]). 0.6773305895427862\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 35)]). 0.6703432674209276\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 35)]). 0.6811405544479688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 45)]). 0.6810893428822359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 60)]). 0.6869270578026772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 60)]). 0.6876821095744768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 60)]). 0.672881867736578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6723437632123629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.674601341287295\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.672234925131003\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.664355049530665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6753308599193891\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6966542402903239\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.7064798263212045\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6914207364122072\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.692637711763382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6722667751212915\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6789123887817065\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6813468746840954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6760570704936981\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6856095989545187\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6988032062848409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 25)]). 0.6774406308929125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6727301341791948\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6732756334046522\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6950895537932714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6755557656288147\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6834533798197905\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6770540612439314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6760466856261095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6723935902118683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6763935244331757\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6740422286093235\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6745459772646427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6727833822369576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6740354572733244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6733210111657778\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6796089212099711\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6958191866676012\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.693397885809342\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6919087121884028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 25)]). 0.6764995511621237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 25)]). 0.6723883574207624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 25)]). 0.6729321976502737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 35)]). 0.6755982600152493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6724644688268503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 45)]). 0.6725059971213341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 45)]). 0.6735398011902968\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 45)]). 0.6709539306660494\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 45)]). 0.683509174734354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6744379339118799\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6798601485788822\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6911570938924948\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6931251212954521\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6849179876347383\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.49648321978747845\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.4351347644502918\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.3867663121782243\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.36914825191100437\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.4159100304823369\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.41609406234541285\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.49756354458319646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6759567285577456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.673529410113891\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.6803423936168352\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.6826803733905157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6724050665895144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6725445811947187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 00:59:38,576\tWARNING util.py:244 -- The `callbacks.on_trial_result` operation took 0.515 s, which may be a performance bottleneck.\n",
      "2023-05-01 00:59:38,578\tWARNING util.py:244 -- The `process_trial_result` operation took 0.517 s, which may be a performance bottleneck.\n",
      "2023-05-01 00:59:38,578\tWARNING util.py:244 -- Processing trial results took 0.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 00:59:38,579\tWARNING util.py:244 -- The `process_trial_result` operation took 0.518 s, which may be a performance bottleneck.\n",
      "2023-05-01 00:59:38,578\tWARNING util.py:244 -- The `process_trial_result` operation took 0.517 s, which may be a performance bottleneck.\n",
      "2023-05-01 00:59:38,578\tWARNING util.py:244 -- Processing trial results took 0.517 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 00:59:38,579\tWARNING util.py:244 -- The `process_trial_result` operation took 0.518 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6716407338778178\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6829674703379472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 35)]). 0.6728899218142033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6762134544551373\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.677464634180069\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.698215035100778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 35)]). 0.6735539721945921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 35)]). 0.6746811121702194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6740378513932228\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6747219897806644\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6831467337906361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6737217158079147\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6757923327386379\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6704926900565624\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6951849100490411\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6899194804330667\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6713254991918802\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.38228284443418187\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.36689890214862925\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.37812431536925334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6748000358541807\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6963531697789828\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6930484995245934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6755170052250227\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6823844710985819\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6995585163434347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6779735883076986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6734088932474455\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6821985989809036\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6885933081309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6726380760471026\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6777653048435847\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6805580680569013\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6910369272033373\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6922276616096497\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6979904224475225\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.679284026225408\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.7021497140328089\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.46221141951779526\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.3612206516166528\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.3748963262575368\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.3821074328540514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6736631914973259\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.673503652215004\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6874338214596113\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6916676883896192\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.5914498524119457\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.40695327054709196\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.4029033745949467\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.4115632902830839\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.37678386045930284\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.3989636565092951\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.3917332950901861\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.4741949030819039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6736779063940048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6741944961249828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 25)]). 0.6734697620073954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 25)]). 0.6741117350757122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 25)]). 0.6755313873291016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.6782618463039398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 35)]). 0.6726223304867744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.674346656848987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 35)]). 0.6826117585102717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6732364309330782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 45)]). 0.6752400485177835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 45)]). 0.6786573876937231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 60)]). 0.6729957088828087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 60)]). 0.673023946583271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 60)]). 0.6801678165793419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6750166701773802\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6856629600127538\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.7047211018701395\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.7008972105880579\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.7024501822888851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6770875590542952\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6761222183704376\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6917254229386648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6761155525843302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.673566959798336\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6739818056424459\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6927705953518549\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.7009433979789416\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6894340167442957\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.4714786186814308\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.4246831505248944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 35)]). 0.6730963674684366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 35)]). 0.6727453793088595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6729482002556324\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6738982486228148\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6802037631471952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6725893132388592\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6821828447282314\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.67535649985075\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6927498442431291\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6912219425042471\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6890107169747353\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6910832996169726\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.7036029025912285\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.710932952662309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6752062737941742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6742003963639339\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.683919157832861\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6854482032358646\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.6998531545201937\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.41722534395133454\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.39765072458734113\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.3928090345580131\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.3696946495523055\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.37019738748980063\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.4539002396826011\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.5414640276964443\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 60)]). 0.4503852957277559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.677623155216376\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6873303279280663\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6773238281408945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6747907474637032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6745001810292403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 25)]). 0.6730649235347906\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 25)]). 0.6890018867949644\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 25)]). 0.6757394646604856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 25)]). 0.6737095105151335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.6764880120754242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 45)]). 0.6995744568606218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 60)]). 0.6738639821608862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6741756039361159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 35)]). 0.673877663910389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6730089721580347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6729911950727304\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6819319985806942\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6922585380574068\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.7047416356702646\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.5732125944147507\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.46514851817240316\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.3834797788100938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 45)]). 0.6752695826192697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6735882249971231\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6879743238290151\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6758941275378069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6737551602224509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6746298310657343\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.680733434855938\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6819555958112081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6761213019490242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6730832022925218\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6726353404422601\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6779637361566225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.675933356086413\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6729855313897133\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 60)]). 0.6831162398060163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 25)]). 0.6814606878906488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 25)]). 0.6725961690147718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 25)]). 0.6750974729657173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 03:04:38,218\tWARNING util.py:244 -- The `callbacks.on_trial_result` operation took 0.570 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:04:38,219\tWARNING util.py:244 -- The `process_trial_result` operation took 0.571 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:04:38,220\tWARNING util.py:244 -- Processing trial results took 0.572 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 03:04:38,221\tWARNING util.py:244 -- The `process_trial_result` operation took 0.573 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:04:38,219\tWARNING util.py:244 -- The `process_trial_result` operation took 0.571 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:04:38,220\tWARNING util.py:244 -- Processing trial results took 0.572 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 03:04:38,221\tWARNING util.py:244 -- The `process_trial_result` operation took 0.573 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 35)]). 0.676493689417839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6741247127453486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.2), ('epoch_number', 45)]). 0.6821569229165713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 45)]). 0.674389086663723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 45)]). 0.6736615362266699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 60)]). 0.6729569969077905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 60)]). 0.6736152147253355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6734706747035185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 60)]). 0.6739320854345957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6820636602739493\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6843672084311644\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.6846642531454563\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.7097929169734319\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 25)]). 0.7017662636935711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.6726178377866745\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.6714837551116943\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.6811368303994337\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.696694710602363\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 25)]). 0.697200883179903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 25)]). 0.674507857610782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 25)]). 0.6859074508150419\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 25)]). 0.6721091543634733\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 25)]). 0.6747225647171339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 25)]). 0.6733622290194035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6774026701847712\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6896168241898218\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 35)]). 0.6953113165994486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6759639270603657\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6809774649639925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 03:27:28,699\tWARNING util.py:244 -- The `callbacks.on_trial_result` operation took 0.586 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:27:28,700\tWARNING util.py:244 -- The `process_trial_result` operation took 0.587 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:27:28,701\tWARNING util.py:244 -- Processing trial results took 0.588 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 03:27:28,702\tWARNING util.py:244 -- The `process_trial_result` operation took 0.589 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:27:28,700\tWARNING util.py:244 -- The `process_trial_result` operation took 0.587 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:27:28,701\tWARNING util.py:244 -- Processing trial results took 0.588 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 03:27:28,702\tWARNING util.py:244 -- The `process_trial_result` operation took 0.589 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6948305418094\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.6951781908671061\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.3572689015418291\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.3387794402272751\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 35)]). 0.34774433728307486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 35)]). 0.6753538809716702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 35)]). 0.6742010364929835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6756601333618164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 45)]). 0.6726779354115328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.4), ('epoch_number', 45)]). 0.6758146633704504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6725786452492079\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6637240114311377\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.679847772543629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6762321765224139\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6770116041103998\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 45)]). 0.6863976294795672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.674559668948253\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6913238503038883\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6897600802282492\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.7117564206322035\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4209998636506498\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.38716002623550594\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.3520587454549968\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.43142123902604607\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.5063137856777757\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4596411174473663\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.5369040289272865\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.5734729654892968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6733688612778982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 25)]). 0.6726678883035978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 25)]). 0.6796605288982391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 35)]). 0.6733985344568888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 35)]). 0.6732458087305228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 35)]). 0.6776276553670565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.6), ('epoch_number', 35)]). 0.6786625211437544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 35)]). 0.6731584804753462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.3), ('epoch_number', 45)]). 0.6760333478450775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "2023-05-01 03:55:25,970\tWARNING util.py:244 -- The `callbacks.on_trial_result` operation took 0.611 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:55:25,971\tWARNING util.py:244 -- The `process_trial_result` operation took 0.612 s, which may be a performance bottleneck.\n",
      "2023-05-01 03:55:25,972\tWARNING util.py:244 -- Processing trial results took 0.613 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 03:55:25,972\tWARNING util.py:244 -- The `process_trial_result` operation took 0.613 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 45)]). 0.6786081977188587\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 45)]). 0.6724939992030462\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 45)]). 0.6861007958650589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 256), ('dropout', 0.5), ('epoch_number', 45)]). 0.6735623056689898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.7), ('epoch_number', 45)]). 0.6727699662248293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 256), ('dropout', 0.4), ('epoch_number', 60)]). 0.6732336978117625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6743861312667528\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6775684083501498\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 25)]). 0.6782687529921532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 25)]). 0.6735525466501713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "2023-05-01 04:04:00,352\tWARNING util.py:244 -- The `callbacks.on_trial_result` operation took 0.618 s, which may be a performance bottleneck.\n",
      "2023-05-01 04:04:00,353\tWARNING util.py:244 -- The `process_trial_result` operation took 0.619 s, which may be a performance bottleneck.\n",
      "2023-05-01 04:04:00,354\tWARNING util.py:244 -- Processing trial results took 0.620 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-05-01 04:04:00,355\tWARNING util.py:244 -- The `process_trial_result` operation took 0.621 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 35)]). 0.6767406289776167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6778858788311481\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6737175919115543\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6805776326606671\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6975565701723099\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6771257519721985\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6458215744545063\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6340485184142987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 35)]). 0.6772519995768865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 45)]). 0.6728323598702749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.7), ('epoch_number', 45)]). 0.6730313549439112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6744597802559534\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6877336973945299\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6797107396026453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6742434352636337\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6924431025981903\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6924978519479433\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.6989585037032763\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.7034179071585337\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.7041489779949188\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.708700696627299\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.44258744704226655\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.425511605416735\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.3931226196388404\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.4564439084691306\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.2), ('epoch_number', 60)]). 0.5082117567459742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6762919723987579\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6754943194488684\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6869278314212958\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.7001436601082484\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.6926708109676838\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4098902279511094\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.36940652776199084\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4453507451495777\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4648977800582846\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4282022996339947\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.47053780674468726\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.3), ('epoch_number', 60)]). 0.4270353779817621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6746510577698549\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.6826746563116709\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 16), ('hidden_dim', 512), ('dropout', 0.5), ('epoch_number', 60)]). 0.7039610048135122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m dict_items([('batch_size', 32), ('hidden_dim', 512), ('dropout', 0.6), ('epoch_number', 60)]). 0.6728263745705286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "\u001b[2m\u001b[36m(train_lstm pid=18488)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "2023-05-01 04:35:41,668\tINFO tune.py:945 -- Total run time: 26394.93 seconds (26392.98 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_model = tune.with_resources(train_lstm, {\"cpu\": 6, 'gpu': 1})\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_model,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=10,\n",
    "        scheduler=ASHAScheduler(metric=\"val_loss\", mode=\"max\"),\n",
    "    ),\n",
    "    param_space=search_space,\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >,\n",
       " <Axes: >]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = {result.log_dir: result.metrics_dataframe for result in results}\n",
    "[d.val_loss.plot() for d in dfs.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = None\n",
    "min_ = 11\n",
    "\n",
    "for t in results:\n",
    "    m = t.metrics_dataframe.val_loss.min()\n",
    "    if min_ > m:\n",
    "        min_ = m\n",
    "        best = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best.metrics_dataframe.val_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'834_batch_size=16,dropout=0.5000,epoch_number=35,hidden_dim=512'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.metrics['experiment_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'E:/Programming/DL_CurseWork/models/back.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiazz0\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(\n",
    "    embeding_m=model_w2v,\n",
    "    hidden_dim=512,\n",
    "    output_dim=2,\n",
    "    n_layers=2,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to('cuda')\n",
    "criterion = criterion.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Training loss: 0.6769307116982798 val_loss: 0.6696794629096985\n",
      "#2 Training loss: 0.6669191035328719 val_loss: 0.67168128490448\n",
      "#4 Training loss: 0.6578714484890933 val_loss: 0.6729620695114136\n",
      "#6 Training loss: 0.6514203444359794 val_loss: 0.6869218349456787\n",
      "#8 Training loss: 0.6503283532838973 val_loss: 0.6785816550254822\n",
      "#10 Training loss: 0.6508760837020067 val_loss: 0.7011358141899109\n",
      "#12 Training loss: 0.6500380127518265 val_loss: 0.6966924071311951\n",
      "#14 Training loss: 0.6488031874258051 val_loss: 0.7187262773513794\n",
      "#16 Training loss: 0.593966223733135 val_loss: 0.48515579104423523\n",
      "#18 Training loss: 0.38986645315690016 val_loss: 0.42558538913726807\n",
      "#20 Training loss: 0.3561793826717548 val_loss: 0.38567933440208435\n",
      "#22 Training loss: 0.3074768580417469 val_loss: 0.4164569079875946\n",
      "#24 Training loss: 0.28334414842661726 val_loss: 0.3906494975090027\n",
      "#26 Training loss: 0.26490157454338653 val_loss: 0.3471037447452545\n",
      "#28 Training loss: 0.24953025417826163 val_loss: 0.34560975432395935\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 28 + 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        predictions = model(X_batch.cuda())\n",
    "        loss = criterion(predictions, y_batch.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = 0, 0\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            predictions = model(X_batch.cuda())\n",
    "            loss = criterion(predictions, y_batch.cuda()).item()\n",
    "            acc = accuracy_score(y_batch, predictions.argmax(dim=1).cpu().detach()).item()\n",
    "            val_loss += loss\n",
    "            val_acc += acc\n",
    "      \n",
    "    if epoch % 2 == 0:\n",
    "      print(f'#{epoch} Training loss: {epoch_loss / len(train_loader)} val_loss: {val_loss / len(test_loader)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       295\n",
      "           1       0.90      0.89      0.90       461\n",
      "\n",
      "    accuracy                           0.87       756\n",
      "   macro avg       0.87      0.87      0.87       756\n",
      "weighted avg       0.87      0.87      0.87       756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "predictions = model(X_batch.cuda()).argmax(dim=1).cpu().detach()\n",
    "print(classification_report(y_batch, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'E:\\Programming\\DL_CurseWork\\models/bf084f090.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "review = 'отзыв о кафе грейс: К сожалению, наш поход в данное заведение нам совершенно не понравился. Уже с самого начала все незаладилось, после того, как нас 20 минут не могли посадить и еще столько же принять заказ. Прождав 30 минут, мы сами взяли кофе со стойки и шарлотку, которая оказалась сухой. Единственное, нужно отдать должное менеджер пытался координировать персонал, но это особо не помогало. Организации абсолютно не было, что испортило наш визит'\n",
    "model.eval()\n",
    "x = train_dataset.vectorize(review).unsqueeze(0)\n",
    "predictions = model(x).argmax(dim=1).cpu().detach()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "review = 'отзыв о кафе грейс: наш поход в данное заведение нам совершенно понравился'\n",
    "model.eval()\n",
    "x = train_dataset.vectorize(review).unsqueeze(0)\n",
    "predictions = model(x).argmax(dim=1).cpu().detach()\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
